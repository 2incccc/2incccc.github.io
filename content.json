{"meta":{"title":"Blog by 2inc","subtitle":"  ","description":"永远相信美好的事情即将发生","author":"zinan2inc","url":"https://2incccc.github.io","root":"/"},"pages":[{"title":"categories","date":"2023-01-16T05:48:55.000Z","updated":"2025-01-27T07:13:44.067Z","comments":false,"path":"categories/index.html","permalink":"https://2incccc.github.io/categories/index.html","excerpt":"","text":""},{"title":"关于我","date":"2023-01-15T13:13:40.000Z","updated":"2025-01-27T07:13:44.067Z","comments":true,"path":"about/index.html","permalink":"https://2incccc.github.io/about/index.html","excerpt":"","text":"欢迎来到我的博客 Welcome To My Blog INFJ，希望是一个能够自洽的人。爱生活，爱家人，爱自己。 目前就读于北京邮电大学电子信息工程专业，主要感兴趣的研究方向围绕多媒体相关，业余热衷一切与音乐有关的东西，时常希望自己还能多发展一些其他领域的爱好，做一个有内涵的人。 可能是理想主义者，有很多不知道是否可以实现的梦想，比如成为独立音乐制作人，比如世界和平… Contact 大部分的社交方式也列举在博客主页中（会持续更新）。欢迎大家选择喜欢的方式联系我。 关于名字，我可以是2inc，可以是zync，可以是zinan2inc，可以是zynestro，未来或许还有更多可能，我也常常随便用几个字母作为我小号的马甲，毕竟名字只是代号罢了（笑 Email : zinan2inc@163.com - 这是我最主要使用的邮箱地址，应该会长久使用，欢迎联系我。 Github : 2incccc - 未来会是主要的开源代码集中地，希望自己可以多写代码，哎沉淀… Gitee 小红书 bilibili 知乎 微信公众号 豆瓣 网易云音乐 微信读书"},{"title":"","date":"2025-01-27T07:13:44.067Z","updated":"2025-01-27T07:13:44.067Z","comments":true,"path":"css/custom.css","permalink":"https://2incccc.github.io/css/custom.css","excerpt":"","text":":root { --first-screen-font-color-light: #edf9e5; --first-screen-font-color-dark: #ffffff; --first-screen-icon-color-light: #e4eadc; --first-screen-icon-color-dark: #ffffff; --first-screen-header-font-color-light: #78fa22; --first-screen-header-font-color-dark:#ffffff; }"},{"title":"photos","date":"2024-07-13T07:16:00.000Z","updated":"2025-01-27T07:13:44.092Z","comments":true,"path":"photos/index.html","permalink":"https://2incccc.github.io/photos/index.html","excerpt":"","text":"即将更新…"},{"title":"","date":"2025-01-27T07:13:44.092Z","updated":"2025-01-27T07:13:44.092Z","comments":true,"path":"js/custom.js","permalink":"https://2incccc.github.io/js/custom.js","excerpt":"","text":"if (!window.runningTime) { window.runningTime = () => { const infoBox = document.querySelector('.footer .website-info-box') const tempDiv = document.createElement('div'); tempDiv.setAttribute('class', 'info-item default') infoBox.appendChild(tempDiv) const since = '2022-08-16 00:00:00' const formatTimestamp = (timestamp) => { const now = Date.now() const timeDiff = Math.abs(now - timestamp) const days = Math.floor(timeDiff / (1000 * 60 * 60 * 24)) const hours = Math.floor((timeDiff % (1000 * 60 * 60 * 24)) / (1000 * 60 * 60)) const minutes = Math.floor((timeDiff % (1000 * 60 * 60)) / (1000 * 60)) const seconds = Math.floor((timeDiff % (1000 * 60)) / 1000) return `${days} 天 ${hours} 小时 ${minutes} 分 ${seconds} 秒` } setInterval(() => { tempDiv.innerHTML = '本站已安全运行 ' + formatTimestamp(new Date(since).getTime()) }, 1000) } } window.runningTime()"},{"title":"links","date":"2024-07-24T05:06:06.000Z","updated":"2025-01-27T07:13:44.092Z","comments":true,"path":"links/index.html","permalink":"https://2incccc.github.io/links/index.html","excerpt":"","text":"若要交换友链，请先将本站添加到你的友链列表里，然后按下列&lt;&lt;示例格式&gt;&gt;留言： 1234- name: # 博主名 link: # 博客链接 description: # 描述 avatar: # 头像，提供图床链接"},{"title":"关于站点","date":"2023-01-17T13:13:40.000Z","updated":"2025-01-27T07:13:44.092Z","comments":true,"path":"site/index.html","permalink":"https://2incccc.github.io/site/index.html","excerpt":"","text":"2022年暑期 偶然了解到hexo博客框架，恰好也有兴趣在网络上搭建一个记录分享自己学习、生活的空间，（也是为激励自己不断进步），便由此开始了折腾的过程。 hexo博客搭建极易上手，但是折腾人的地方在于对主题文件的配置以及自定义。出于对美感(花里胡哨)的追求，至今（2023/1/16）我尝试更换了多种主题butterfly NexT Fluid Volantis Nexmoe matery 等等， 最终到现在在用的 Yun。 2023年1月 目前该主题配置基本已完成，下一步将尝试搭建可靠的图床方便图片加载（github图床的jsDelivr感觉还是慢，本地图床又太折腾），当然也会慢慢补全先前的笔记文章等，扩充博客内容。此外，由于关于博客部分目前内容尚少，随着时间推移内容扩充后会考虑新建关于站点的超链接并在侧边栏重新渲染。–1/16 完成Yun主题的基本配置----1/16 由于LeveRE 评论系统自带广告，决定更换到waline系统，采用LeanCloud作为数据库，Vercel用于部署服务端----1/17 借助instantlogodesign设计logo,更新网站log----1/20 2023年6月 过去的一个学期博客被我咕咕咕了，暑假来了有时间，该及时更新力 更新过去的一学期里的数篇文章，调整博客和个人的关于页面----6/23 2024年7月 一年啊一年，似乎已经习惯了以年为单位更新了（bushi 更换主题为更简洁的keep，也以此名字激励自己接下来的时间要保持更新。 希望自己可以聚焦在内容上，而不是花里胡哨的主题装饰上 针对更新后的主题，修改了部分标签页的配置。----7/24 #TODO：配置博客的相册页 #TODO: 更新过去一年的博客内容 #TODO: 解决inject特性无法使用的问题，以实现自定义样式 #TODO: 更新个人页面联系方式"},{"title":"tags","date":"2023-01-15T13:16:34.000Z","updated":"2025-01-27T07:13:44.092Z","comments":true,"path":"tags/index.html","permalink":"https://2incccc.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"如何使用CMake构建JUCE项目（不使用Projucer）","slug":"juce-cmake","date":"2025-01-27T07:37:06.000Z","updated":"2025-01-27T07:57:33.592Z","comments":true,"path":"2025/01/27/juce-cmake/","link":"","permalink":"https://2incccc.github.io/2025/01/27/juce-cmake/","excerpt":"","text":"最近对VST开发比较感兴趣，发现了JUCE框架，但是JUCE提供的 Projucer 大多配合 Xcode 使用，本人更习惯使用VS Code，又了解到 Projucer 其实只是相当于 CMake 构建项目的 GUI 界面，所以在下面介绍一种VS Code 可以使用的 JUCE 项目构建方法。 JUCE 是一个流行的 C++ 框架，广泛用于音频和 GUI 应用的开发。通常，JUCE 提供的 Projucer 可用于生成工程文件，但如果你希望使用 CMake 直接构建 JUCE 项目，那么本文将指导你如何完成这一过程。 1. 环境准备 在开始之前，请确保你的开发环境满足以下条件： JUCE 库：已下载并解压 JUCE 源码 CMake：已安装 CMake（推荐 3.15 及以上版本） 编译工具链：例如 GCC、Clang，或 Windows 上的 Visual Studio 编译工具 2. 创建 CMakeLists.txt 在你的 JUCE 项目根目录下，创建 CMakeLists.txt 文件，并填入以下内容： 1234567891011121314151617181920212223# 指定 CMake 版本cmake_minimum_required(VERSION 3.15)# 定义项目名称project(MyJUCEApp)# 设置 JUCE 库路径（修改为你的 JUCE 目录）set(JUCE_DIR /path/to/juce)# 引入 JUCEadd_subdirectory($&#123;JUCE_DIR&#125; JUCE)# 定义可执行文件add_executable(MyJUCEApp Source/Main.cpp Source/MainComponent.cpp)# 链接 JUCE 库target_link_libraries(MyJUCEApp PRIVATE juce::juce_gui_basics juce::juce_audio_basics)# 设置 C++ 标准set_target_properties(MyJUCEApp PROPERTIES CXX_STANDARD 17) 注意： 修改 JUCE_DIR：请替换 /path/to/juce 为你的实际 JUCE 路径。 添加更多 JUCE 模块：如果你的项目需要更多模块，可以在 target_link_libraries 里添加，例如 juce::juce_audio_processors。 3. 配置和编译项目 接下来，按照以下步骤编译项目： 创建构建目录 12mkdir buildcd build 运行 CMake 配置 1cmake .. 编译项目 1cmake --build . 如果一切顺利，你的可执行文件将被生成在 build 目录中。 4. 运行程序 编译完成后，你可以直接运行生成的可执行文件，例如： 1./MyJUCEApp 在 Windows 上，你可以双击 MyJUCEApp.exe 或使用命令行运行。 5. 其他配置 JUCE 模块选择 根据你的需求，添加适当的 JUCE 模块，例如： 1target_link_libraries(MyJUCEApp PRIVATE juce::juce_gui_basics juce::juce_audio_processors) 平台特定设置 如果你的项目需要在多个平台上运行，可以添加不同的配置： 1234567if(WIN32) # Windows-specific settingselseif(APPLE) # macOS-specific settingselseif(UNIX) # Linux-specific settingsendif() 包含自定义模块 如果你有自己的模块，可以使用 add_subdirectory 或 include_directories 进行添加。 总结 本文介绍了如何使用 CMake 构建 JUCE 项目，完全绕过 Projucer，并展示了如何配置 CMakeLists.txt 以及执行编译。 如果你在构建过程中遇到问题，欢迎留言讨论！","categories":[{"name":"juce开发","slug":"juce开发","permalink":"https://2incccc.github.io/categories/juce%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"juce","slug":"juce","permalink":"https://2incccc.github.io/tags/juce/"},{"name":"cmake","slug":"cmake","permalink":"https://2incccc.github.io/tags/cmake/"}]},{"title":"基于飞书的个人工作流分享","slug":"基于飞书的个人工作流分享","date":"2024-07-24T17:41:14.000Z","updated":"2025-01-27T07:13:44.066Z","comments":true,"path":"2024/07/25/基于飞书的个人工作流分享/","link":"","permalink":"https://2incccc.github.io/2024/07/25/%E5%9F%BA%E4%BA%8E%E9%A3%9E%E4%B9%A6%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%B7%A5%E4%BD%9C%E6%B5%81%E5%88%86%E4%BA%AB/","excerpt":"","text":"","categories":[],"tags":[{"name":"工具","slug":"工具","permalink":"https://2incccc.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"name":"效率","slug":"效率","permalink":"https://2incccc.github.io/tags/%E6%95%88%E7%8E%87/"},{"name":"经验分享","slug":"经验分享","permalink":"https://2incccc.github.io/tags/%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB/"}]},{"title":"论文笔记节选","slug":"论文笔记节选","date":"2024-05-24T16:31:58.000Z","updated":"2025-01-27T07:13:44.066Z","comments":true,"path":"2024/05/25/论文笔记节选/","link":"","permalink":"https://2incccc.github.io/2024/05/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E8%8A%82%E9%80%89/","excerpt":"本篇内容主要为实习期间主要研究的几篇论文的笔记内容，在此留档，主要涉及舞蹈生成方向、音频生成等。","text":"本篇内容主要为实习期间主要学习的几篇论文的笔记内容，在此留档，主要涉及舞蹈生成方向、音频生成等。 @huangEnhancingExpressivenessDance2024 title:Enhancing Expressiveness in Dance Generation Via Integrating Frequency and Music Style Information 提高舞蹈动作的表现力 Abstract 提出了 ExpressiveBailando 针对流派匹配、节拍对齐、舞蹈动态三个方面，提出了衡量表现力 Expressiveness 的要素 流派/节拍：一个预先训练的音乐模型：Mert 动态表现：将频率信息纳入 VQ-VAE,Frequency Complemented VQ-VAE FreqVQ-VAE Inroduction 流派/节拍：意味着舞蹈和音乐的和谐匹配程度 舞蹈动态相对抽象一点， 和表演方式、动作形式联系起来，主要与动作速度有关 Methods 这张架构图展示了 ExpressiveBailando 的总体结构，具体讲解如下： 整体概述 ExpressiveBailando 是一个用于生成高表现力舞蹈的系统。该系统利用音乐特征和舞蹈编码，通过频率补充 VQ-VAE（FreqVQ-VAE）和跨条件 GPT 生成舞蹈。 各部分的详细解释 音乐处理部分： MERT：预训练的音乐模型 MERT 用于提取音乐特征。这些特征包含丰富的音乐风格信息（如类型和节奏）。 CONV：卷积层将 MERT 特征下采样。 Handcrafted music features：手工制作的音乐特征，如 MFCC（梅尔频率倒谱系数），与 MERT 特征一起作为音乐条件输入。 舞蹈处理部分： Upper body FreqVQ-VAE Encoder：对上半身舞蹈序列进行编码，生成上半身姿态编码。 Lower body FreqVQ-VAE Encoder：对下半身舞蹈序列进行编码，生成下半身姿态编码。 Codebook Zu 和 Z：分别保存上半身和下半身的编码字典，每个条目代表一个有意义的舞蹈姿态。 跨条件 GPT： Positional Embedding：将上半身姿态编码、下半身姿态编码与音乐条件输入进行位置嵌入。 Cross-Conditional GPT：根据输入的音乐和初始姿态编码生成未来的上半身和下半身姿态编码（au 和 al）。 Top-1 Selection：选择最有可能的姿态编码。 解码部分： Upper body FreqVQ-VAE Decoder：根据上半身姿态编码生成上半身的舞蹈序列。 Lower body FreqVQ-VAE Decoder：根据下半身姿态编码生成下半身的舞蹈序列。 Future Dance：最终生成的 未来舞蹈序列，由上半身和下半身的舞蹈序列组成。 工作流程 音乐输入到 MERT，提取出音乐特征后通过卷积层下采样，与手工制作的音乐特征一起形成音乐条件输入。 舞蹈输入分别通过上半身和下半身的 FreqVQ-VAE 编码器，生成姿态编码。 将这些编码与音乐条件输入进行位置嵌入，然后输入跨条件 GPT，生成未来的上半身和下半身姿态编码。 根据生成的姿态编码，通过 FreqVQ-VAE 解码器生成未来的舞蹈序列。 目的 这种架构通过结合频率信息和音乐风格信息，改进了舞蹈的类型匹配、节奏对齐和舞蹈动态性，增强了生成舞蹈的表现力。 @liExploringMultiModalControl2024 title:Exploring Multi-Modal Control in Music-Driven Dance Generation 舞蹈动作的多模态控制 Abstract 聚焦于生成过程中的输入信号控制 一个可以实现多模态控制的生成框架 控制和生成是分开的 对于不同类别的信号采取不同的策略 Inroduction 在同一个框架实现多模态控制： 风格控制 基于文本的语义控制 对于关键帧的动作控制 Methods 这张图展示了提出的方法的整体流程，分为预训练、协同训练和推理三个阶段。以下是每个阶段的详细解释： 预训练：VQ-VAE Motion VQ-VAE： 动作片段（Mm 和 Mt）被输入编码器，编码为离散的动作编码（Tokens）。 解码器将编码解码回原始舞蹈动作。 通过这种方式，所有动作片段被转换为离散的动作编码，这些编码表示共享的潜在空间。 协同训练：带控制模块的跨模态 GPT Text2Motion GPT： CLIP：用于提取文本特征 T。 T-Base：文本 Transformer 基础层，用于处理文本特征。 Transformer Head Layer：与音乐到舞蹈 GPT 共享的头层。 训练目标：最大化数据分布的对数似然（Lrecon），以预测动作编码。 Music2Dance GPT： MLP：多层感知器，用于提取音乐特征 M。 M-Base：音乐 Transformer 基础层，用于处理音乐特征。 Transformer Head Layer：与 Text2Motion GPT 共享的头层。 Genre Control：类型嵌入网络（GEN）和多类型判别器，用于实现类型控制。 Mask Attention/Causal Attention：遮掩注意力/因果注意力机制，用于实现关键帧控制。 训练目标：多类型舞蹈判别器（Lgenre），确保生成的舞蹈符合给定的类型。 推理阶段：统一可控舞蹈生成框架 统一框架： Music：输入音乐，通过 MLP 提取音乐特征 M。 Genre Control：通过 GEN 生成类型嵌入 G。 控制模块： M-Base：用于处理音乐特征。 Text Control Module：处理文本特征并进行语义控制。 Mask Attention/Causal Attention：实现关键帧控制或序列生成。 Transformer Head Layer：共享的头层，用于处理特征并预测动作编码。 Decoder：将预测的动作编码解码为舞蹈序列。 详细流程 预训练 Motion VQ-VAE： 将舞蹈动作编码为离散的动作编码，通过解码器重建舞蹈。 协同训练跨模态 GPT： Text2Motion GPT：使用 CLIP 提取文本特征，通过 T-Base 处理，并通过共享的 Transformer Head Layer 预测动作编码。 Music2Dance GPT：使用 MLP 提取音乐特征，通过 M-Base 处理，并通过共享的 Transformer Head Layer 预测动作编码。 多模态控制： 文本控制：融合音乐和文本特征，实现语义控制。 类型控制：通过类型嵌入网络和判别器，实现类型控制。 关键帧控制：通过遮掩注意力机制，实现关键帧控制。 推理阶段： 输入音乐，通过 MLP 提取音乐特征。 通过类型嵌入网络生成类型嵌入。 控制模块处理音乐和文本特征，通过共享的 Transformer Head Layer 预测动作编码。 通过解码器将预测的动作编码解码为舞蹈序列。 这种方法通过解耦舞蹈生成和控制，确保了生成舞蹈的高质量，同时实现了多模态控制，包括类型控制、语义控制和关键帧控制。 liuLearningHierarchicalCrossModal2022 Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation Abstract 研究问题：根据语音生成一致的手势与动作 提出了 Hierarchical Audio-to-Gesture (HA2G) for co-speech gesture generation 用于生成协同语音手势的分层音频到手势 (HA2G) 制定基于音频文本对齐的对比学习策略，以获得更好的音频表示 Inroduction 动作和手势在语言交流传达意思中很重要 传统上，是将语音和动作一一对应下来，效果并不好，更好的是数据驱动的深度学习方法 两个观察结果： 1）不同类型的协同语音手势与不同级别的音频信息相关。例如，隐喻手势与高级语音语义密切相关（例如，在描绘峡谷时，人们会将两只伸出的手分开并说“间隙”），而节拍和音量等低级音频特征则与高级语音语义密切相关。到有节奏的手势。 2）不同人体部位在协同语音手势中的动态模式并不相同，例如灵活的手指和相对静止的上臂。因此，像以前的研究一样生成整个上半身姿势是不合适的 整个框架包括两个部分，Hierarchical Audio Learner, and the Hierarchical Pose Inferer. 分层音频学习器以及分层姿势推断器 分层音频学习器：提取分层音频特征并通过对比学习呈现判别性表示。 分层姿势推断器：学习多级特征和人体部位之间的关联。因此，人体姿势以级联方式生成。 Related Work Human-Centered Audio-Visual Learning：音频-视觉，主要局限在舞蹈生成、面部表情生成中，不如手势生成更复杂 Human Motion Synthesis：人类动作合成：计算机图形学的重要课题 Audio/Text-Driven Motion Generation：建议对文本、音频、说话者身份的三模态特征嵌入进行编码，并将它们连接在一起以传递解码器。… Approach 这张流程图描述了一个语音驱动的手势生成框架。这个框架通过学习语音和手势之间的层次化关系来生成与语音同步的手势动作。流程图可以分为几个主要部分，每个部分执行不同的功能： Hierarchical Audio Learner（分层音频学习器）: 输入语音（a）和文本（t）。 通过不同的神经网络层次来提取语音的不同层次的特征（低、中、高）。 这些特征用于正面和负面样本的对比学习，通过 L_multi 损失函数来优化。 Hierarchical Pose Inferer（分层姿态推断器）: 利用一个编码器 E_ID，它接收视频帧（I）作为输入，提取与身份相关的特征（f_id）。 这些特征与从 Hierarchical Audio Learner 获得的音频特征一起，通过多个 GRU（门控循环单元）网络层来逐步预测姿态。 每个 GRU 层负责生成一组特定的姿态细节，这些层次结构预测从粗糙到细粒度的姿态。 使用 softmax 进行样式采样，以便选择特定的手势样式。 输出: 多个不同层次的预测手势（(\\hat{P}^1) 到 (\\hat{P}^6)）。 这些预测被一起优化，以减少与真实手势之间的差异，使用层次性 Huber 损失函数。 损失函数: L_KLD 和 L_style 用于控制生成的手势的多样性和风格。 L_GAN和L_phy可能用于增强手势的自然性和物理合理性。 总体而言，该框架的目标是利用文本和语音输入来生成与之对应的、自然流畅的手势动作。这个过程涉及深度学习和神经网络，特别是对比学习和循环神经网络，以模拟人类的手势和动作。 tsengEDGEEditableDance2022 EDGE: Editable Dance Generation From Music Abstract 可编辑的舞蹈生成方法 EDGE 使用基于 Transformer 的扩散模型，与强大的音乐特征提取器 Jukebox 配合使用，并赋予非常适合舞蹈的强大编辑功能，包括联合调节和中间处理。 Inroduction 先前研究 音乐生成舞蹈并不是很能让人满意 对生成舞蹈的评估往往是有缺陷的 根据输入音乐创建逼真、物理上合理的舞蹈动作 贡献： 基于 Diffusion 的 EDGE 方法 分析了以前工作的指标，表明不好 使用新颖的接触一致性损失来消除运动中的脚滑动物理不可信行，引入物理足接触分数 利用 Jukebox 的音频特征提取 Related Work 动作生成 早期属于运动匹配的范畴，插值进行操作 深度学习领域，往往会忽略了物理上的真实性 舞蹈生成 遵循动作检索范例 在大量数据集训练 我们提出一个简单目标训练的单一模型 生成扩散模型 生成建模的有效途径 生成以文本为条件的运动方面 以音乐为条件，难度更大 Method 姿势的建摸：24 个关节，每个关节 6 个自由度，和单独的脚步的建模 24* 6+3=147，每只脚，2 个接触标签，共 151 维度 扩散框架： 辅助损失，四种 编辑功能， 固定部分帧，推理其他帧 tsengMusictoDancePoseLearning2024a Music-to-Dance Poses: Learning to Retrieve Dance Poses from Music 从音乐中检索舞蹈 Abstract 🔤EDSA 适配器是一种利用编码器-解码器转换的自注意力适配器，可以有效且高效地对大规模预训练音乐模型进行微调，以学习从音乐片段到 3D 人体姿势和形状的投影。🔤 EDSA 适配器，利用编码器-解码器转换的子注意力适配器，用于微调模型 将预训练的大规模音乐模型微调为能够将音乐片段投影到3D 人体姿态和形状参数上的模型 Inroduction 没有将其看作生成任务，而是看作跨模态的检索任务，输入上一刻动作输出下一刻 将预训练的大规模音乐模型微调为能够将音乐片段投影到3D 人体姿态和形状参数上的模型 EDSA 适配器，利用编码器-解码器转换的子注意力适配器，用于微调模型 相当于直接打通了音乐-&gt;动作的过程 Methods xieEnhancingAudioGeneration2024 Enhancing Audio Generation Diversity with Visual Information利用视觉信息增强音频生成的多样性 Abstract 利用视觉信息 指导音频内容的生成 Inroduction 由文本生成音频引入，TTA DCASE2023 task7 [1] provides a dataset for categorybased audio generation 问题：训练集的音频比模型生成的更多样，原因是更多隐式的特征无法被学习 how 对训练集音频采用无监督聚类方法，得到更细致的分类 为体现 audio-vision 对齐，对其对细致的分类使用互联网上的图像，共同输入进模型 提出了一个新的框架 训练过程： 基于训练集无监督聚类，之后自行添加图片作为输入，将 label 和 image 进行 fusion 得到新的输入，然后将对应的音频经过编码器得到了 audio representation, 模型主要学习如何从融合输入预测 represention。此外，需要用训练集音频训练Vocoder 推理过程，新的融合信息，进入模型得到对应的 represention，然后经过 decoder 得到频谱，然后进入 vocoder 得到音频 Methods Modal Fusion Music Representations VAE VQ-VAE (所以原理是什么？) Token Prediction 基于自回归的(transformer 基于扩散的 LDM Experimental 两种框架 VAE&amp;LDM VQ-VAE&amp;Transformer Results and discussions 评价指标 客观 Quality: FAD，和参考样本的对比 Diversity: Mean Squared Distance 均方距离 主观（评测） Conclusions 基于视觉信息，增强音频生成的质量和多样性 Summary 视觉-&gt;听觉 单纯基于图片生成音频？ 基于视频生成背景音乐？ zhuHumanMotionGeneration2023 Human Motion Generation: A Survey 综述 Abstract 研究范围：基于条件信号（文本、音频、场景）生成人体运动 该领域的首次综述 Inroduction 生成方法：自回归模型、变分自编码器 (VAE) 、归一化流 、生成对抗网络 (GAN) 和去噪扩散概率模型 (DDPM) 建模技术的进步，使得数据集收集更加方便 三个问题（挑战） 动作本身是复杂、非线性的，运动机理复杂，视觉上合理性 要和条件信息相符合一致 注意一些潜在反应内容的因素 章节section梗概 2 介绍范围 3 基础知识介绍 4-6 介绍总结方法 Preliminaries 预备知识 Motion Data Representation 基于关节 基于旋转 SMPL Motion Data Collection 基于标记的 光学标记 传感器标记（动捕） 不基于标记的 借助计算机视觉算法 伪标记 通过 estimator 估计后生成 手动打标 类似 mmd 的原理 Motion Generation Methods 基于回归模型的 监督学习，从给定条件信号构建目标生成动作 基于生成模型的 Generativa Adversarial Networks 生成对抗网络 Variational Autoencoders 变分自动编码器 Normalizing Flows 归一化流 Diffusion Models 扩散模型 Motion Graph 运动图 Methods Text-Conditioned Motion Generation Action to Motion 根据特定的动作类别生成人体动作 往往擅长但动作的运动，多动作复杂序列比较困难 Text to Motion 根据不同的文本描述到更广泛的动作 Audio-Conditioned Motion Generation music to dance 一种方法是直接基于全监督的回归模型，但是多样性缺乏 基于生成模型的方法，GAN/diffuion/VAE/运动图 长时间序列的舞蹈动作生成 Speech to gesture 根据语音音频生成上班深动作，聚焦于人的手势，在交流中发挥重要作用 言语手势存在显著人际差异，没有较好的普遍性 Scene-Conditioned Motion Generation 生成于场景上下文一致的合理人体运动，是计算机图形学和计算机诗句恶的长期存在的问题。 除去动态动作，还包括静态姿势","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://2incccc.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"论文","slug":"论文","permalink":"https://2incccc.github.io/tags/%E8%AE%BA%E6%96%87/"},{"name":"Dance Generation","slug":"Dance-Generation","permalink":"https://2incccc.github.io/tags/Dance-Generation/"},{"name":"Motion Generation","slug":"Motion-Generation","permalink":"https://2incccc.github.io/tags/Motion-Generation/"}]},{"title":"【d2l.ai】经典深度学习网络","slug":"【d2l.ai】经典深度学习网络","date":"2024-03-12T17:05:59.000Z","updated":"2025-01-27T07:13:44.061Z","comments":true,"path":"2024/03/13/【d2l.ai】经典深度学习网络/","link":"","permalink":"https://2incccc.github.io/2024/03/13/%E3%80%90d2l.ai%E3%80%91%E7%BB%8F%E5%85%B8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%BB%9C/","excerpt":"","text":"多层感知机 多层感知机的简洁实现 123456789101112131415161718192021222324252627import torchfrom torch import nnfrom d2l import torch as d2l # 多层感知机的简洁实现import torchfrom torch import nnfrom d2l import torch as d2lnet = nn.Sequential(nn.Flatten(), nn.Linear(784,256), nn.ReLU(), nn.Linear(256,10) )# 建立模型def init_weights(m): if type(m) == nn.Linear: nn.init.normal_(m.weight, std = 0.01) net.apply(init_weights);batch_size, lr, num_epochs = 256, 0.1, 10loss = nn.CrossEntropyLoss(reduction='none')trainer = torch.optim.SGD(net.parameters(), lr=lr)train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)&gt;) 模型选择、欠拟合和过拟合 训练误差：训练数据集上计算得到的误差 泛化误差：（对于其他数据集）在无限多数据样本中模型误差的期望 模型选择 训练集：训练模型，获取参数 验证集：调整模型超参数，并选取最佳参数 测试集：验证模型，训练和验证的过程不能使用测试集 当训练数据稀缺，采用 K 折交叉验证，分出 K 个子集，进行 K 次训练，每次使用不同的子集作为验证集，其余 K -1 个子集作为训练集 总结 模型容量需要匹配数据复杂度 统计机器学习提供数学工具来衡量模型复杂度 实际中一般靠观察训练误差和验证误差 神经网络计算 层和块 一个块可以由许多层组成；一个块可以由许多块组成。 块可以包含代码。 块负责大量的内部处理，包括参数初始化和反向传播。 层和块的顺序连接由 Sequential 块处理。 参数管理 访问参数，用于调试、诊断和可视化； 参数初始化； 在不同模型组件间共享参数。 参数是复合的对象，包含属性、值等等 1nn.init.normal_(m.weight, mean=0, std=0.01) # 替换函数 CNN 卷积神经网络 卷积神经网络（convolutional neural networks，CNN）是机器学习利用自然图像中一些已知结构的创造性方法。 6.1 从全连接层到卷积 两个原则：平移不变性、局部性 重新考量全连接层：权重变为四维，输入输出变为矩阵 6.2 图像卷积 6.3 填充和步幅 假设输入形状为 ，卷积核形状为 ，那么输出形状将是()。 因此，卷积的输出形状取决于输入形状和卷积核的形状。 填充 填充多少行，输出多多少行 通常情况，需要填充 行，使得输入和输出维度相同，此时，、 通常为奇数（1 3 5） 步幅 通常为了高效计算或者缩减采样次数 6.4 多输入多输出通道 6.5 汇聚层 也叫池化层 6.6 卷积神经网络（LeNet） 12345678910111213import torchfrom torch import nnfrom d2l import torch as d2lnet = nn.Sequential( nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2), nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(), nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(), nn.Linear(120, 84), nn.Sigmoid(), nn.Linear(84, 10)) Modern CNN 深度卷积神经网络 AlexNet 本质上是更深更大的 LeNet VGG 使用块的网络 网络中的网络 NiN 对每个像素的位置独立使用全连接层 123456789101112131415161718192021222324import torchfrom torch import nnfrom d2l import torch as d2ldef nin_block(in_channels, out_channels, kernel_size, strides, padding): return nn.Sequential( nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding), nn.ReLU(), nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(), nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU()) net = nn.Sequential( nin_block(1, 96, kernel_size=11, strides=4, padding=0), nn.MaxPool2d(3, stride=2), nin_block(96, 256, kernel_size=5, strides=1, padding=2), nn.MaxPool2d(3, stride=2), nin_block(256, 384, kernel_size=3, strides=1, padding=1), nn.MaxPool2d(3, stride=2), nn.Dropout(0.5),# 标签类别数是10 nin_block(384, 10, kernel_size=3, strides=1, padding=1), nn.AdaptiveAvgPool2d((1, 1)),# 将四维的输出转成二维的输出,其形状为(批量大小,10) nn.Flatten()) 残差网络 ResNet 确保新的映射包含原有的映射，防止网络是退化的 RNN 循环神经网络 循环神经网络可以很好的处理序列信息 序列模型 研究的是序列预测问题： 两个策略：自回归模型和因变量自回归模型 马尔可夫模型 假设当前只跟少数数据相关，简化模型 潜变量模型 潜变量概括历史信息 文本预处理 主要预处理步骤：拆分为次元，建立词表，映射到数字索引 tokenize nlp 中最常见的操作 中文的分词使用 jieba 语言模型和数据集 目标：估计联合概率 面对问题：对文档或者词元序列进行建模 通过计数 常用统计方法：n 元语法，基于马尔可夫的统计模型 随机采样 基于随机的偏移量，不重叠、不相邻地划分序列 corpus, batch_size, num_steps：整个序列、小批量的大小，每一个子序列的长度 顺序分区 保证两个相邻的小批量中的子序列在原始序列上也是相邻的 循环神经网络 对于序列模型的神经网络，RNN 输出、隐变量、观察 隐变量和观察一起作为自变量，控制输出的隐变量 o_t ~ h_t H_t ~ h_t-1, x_t-1 拿掉 h_t-1 退化为 MLP 输出以及隐变量（的计算）在观察之前 观察是用于更新下一个单元，相当于观察既是输入也是标签 有点像因果系统（？），包含了时间信息 困惑度 衡量一个语言模型的好坏可以用平均交叉熵 困惑度取指数，来衡量，是平均每次可能选项 困惑度最好值是 1 梯度剪裁 RNN 的应用 文本生成：一个生多个 文本分类：多个生一个 问答、翻译：同时多个生成同时多个，有时间先后 Tag 生成：对每个词进行生成","categories":[{"name":"d2l.ai","slug":"d2l-ai","permalink":"https://2incccc.github.io/categories/d2l-ai/"}],"tags":[{"name":"d2l.ai","slug":"d2l-ai","permalink":"https://2incccc.github.io/tags/d2l-ai/"},{"name":"深度学习","slug":"深度学习","permalink":"https://2incccc.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"机器学习","slug":"机器学习","permalink":"https://2incccc.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"基于自动机器学习的电信网络诈骗反制实践","slug":"基于自动机器学习的电信网络诈骗反制实践","date":"2024-02-07T16:58:31.000Z","updated":"2025-01-27T07:13:44.066Z","comments":true,"path":"2024/02/08/基于自动机器学习的电信网络诈骗反制实践/","link":"","permalink":"https://2incccc.github.io/2024/02/08/%E5%9F%BA%E4%BA%8E%E8%87%AA%E5%8A%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%94%B5%E4%BF%A1%E7%BD%91%E7%BB%9C%E8%AF%88%E9%AA%97%E5%8F%8D%E5%88%B6%E5%AE%9E%E8%B7%B5/","excerpt":"实习期间涉及的其中一个项目，在这次项目中学习了自动机器学习，在此记录一下。","text":"实习期间涉及的其中一个项目，在这次项目中学习了自动机器学习，在此记录一下。 引言 在数字化时代，电信网络已成为人们日常生活和工作的重要组成部分。然而，随着技术的发展和应用范围的扩大，电信网络诈骗案件也呈现出愈加猖獗的趋势。这些诈骗行为不仅给受害者带来经济损失，同时也对社会稳定和人们的心理安全造成了严重影响。当前，反制电信网络诈骗的手段主要依靠传统的监管政策、法律法规以及人工审核。然而，这些方法往往耗时耗力，随着信息时代的快速到来，这些传统方法往往难以应对诈骗手段的快速迭代和大规模蔓延。 面对此类挑战，机器学习技术的引入为我们提供了新的解决方案。机器学习是人工智能领域的一个重要分支，它能够让机器像人脑一样有能力学习和识别模式，并在没有明确编程的情况下作出决策。通过分析大量电信诈骗案例的数据样本，机器学习模型能够学习得到潜在的诈骗电话特征，并实时预测和拦截可疑通话，从而在源头上减少电信诈骗案件的发生。 在机器学习的传统实践中，整个流程涉及多个环节，包括数据预处理、特征工程、模型选择及优化等关键步骤。针对像电信诈骗案件的实际应用场景，数据往往是非结构化的，包含大量噪声，且特征间的关系复杂，这使得从原始数据中提取有效的信息成为一项艰巨的任务。数据工程师和算法专家需要投入大量的时间和精力，通过专业的技术手段来处理和转化数据这一过程不仅耗时耗力，而且对专业知识的依赖性极强，给机器学习的实际应用带来了不小的挑战。 事实上，随着人工智能技术的不断发展，现在已经有成熟的技术可以解决机器学习技术门槛高的问题：自动化机器学习（AutoML） 。它通过自动化的方式完成模型的选择、特征处理、参数调优等工作，极大地减少了人为干预的需求以及对专业知识的依赖。这不仅降低了整个模型开发过程的技术门槛，还使得非技术背景的从业者也能参与到模型的开发和训练中来。AutoML 的出现使得更多的资源和精力可以集中于解决实际问题，而不是被繁琐的技术细节所困。因此，在电信网络诈骗反制领域，AutoML 的应用无疑会为我们提供更强有力的技术支持。 接下来，本文将从电信网络诈骗的背景出发，简要介绍机器学习及自动化机器学习的相关知识，并通过一个具体的实验流程，展示如何利用 AutoML 技术构建一个使用的的诈骗电话识别模型。通过本文的介绍，读者将能够深入理解机器学习在电信网络诈骗反制实践中的应用价值和潜力。 预备知识 机器学习 什么是机器学习 无关轻重的文字，不做赘述，下同 典型算法简介 自动化机器学习（AutoML） 背景介绍 如前文所述，传统机器学习模型大致可分为以下四个部分：数据采集、数据预处理、优化、应用；其中数据预处理与模型优化部分往往需要具备专业知识的数据科学家来完成，他们建立起了数据到计算的桥梁。然而，即使是数据科学家，也需要花费大量的精力来进行算法与模型的选择。 机器学习在各种应用中的成功，导致对机器学习从业人员的需求不断增长，因此我们希望实现真正意义上的机器学习，让尽可能多的工作也能够被自动化完成，进一步降低机器学习的门槛，让没有该领域专业知识的人也可以使用机器学习来完成相关的工作。 AutoML 旨在使机器学习模型的构建过程更加自动化，从而使数据科学家和工程师能够更有效地工作，甚至使非专家也能利用机器学习技术。它从传统机器学习模型出发，从特征工程、模型构建、超参优化三方面实现自动化；并且也提出了 end-to-end 的解决方案。 与传统机器学习方法相比，AutoML 的优势在于其操作的简便性和整个过程的自动化。用户不需要深入理解每个算法的细节，就可以完成从数据清理到最终模型部署的整个流程。这大大简化了机器学习的应用，使其不仅限于数据科学家或算法工程师，任何对数据有需求的个人或企业都能够利用这项强大的技术。通过 AutoML，机器学习的门槛被大幅降低，其应用范围和潜力也随之大大拓展。 常见框架 关于 AutoML 的实现，学术界和工业界都已提出各种各样的框架，包括开源及闭源框架。下面本文调研了几个常用的开源框架，并将特点总结如下 Auto_ml： Auto_ml 强调广泛的适用性和易用性，支持多种传统机器学习模型，如随机森林和梯度提升机。它提供自动特征工程、模型选择和超参数优化，旨在简化机器学习的整个工作流程。特别适合中小型数据集，并且集成了数据预处理和模型解释性工具，帮助用户更好地理解模型的行为。 FLAML (Fast and Lightweight AutoML)： FLAML 是一款由微软开源的轻量级 Python 库，可以帮助用户快速、高效地找出最佳机器学习模型，支持分类和回归问题。采用成本敏感的优化方法，能够在资源有限的环境下快速提供优化的参数调整。FLAML 是一个用户友好且易于集成的 AutoML 解决方案，特别适合那些需要快速有效地进行机器学习建模的场景。 MLJAR： MLJAR 提供自动化的特征工程、模型选择和超参数调优，使得模型开发过程更加高效。MLJAR 提供 Web 界面和 Python API，使得用户无论是通过图形界面还是编程方式都能轻松使用。它还支持模型的可视化和解释，帮助用户更好地理解和展示他们的结果。 Microsoft 的 Azure AutoML： Azure AutoML 是 Microsoft 提供的一站式机器学习服务，旨在简化机器学习模型的构建、训练和部署。它提供了丰富的数据处理能力，自动特征选择以及广泛的模型选择和调优选项。Azure AutoML 紧密集成在 Azure 云平台上，提供高效的计算资源和易于使用的 Web 界面，使得从数据到部署的整个机器学习流程变得简单快捷。对于企业用户来说，Azure AutoML 还提供了强大的安全性和可扩展性，使得企业可以安心地在云端进行机器学习工作。 Auto-Keras： Auto-Keras 是专门为深度学习设计的 AutoML 系统，提供神经网络架构的自动搜索功能。它使用贝叶斯优化技术进行参数调优，旨在无需深入了解网络架构的情况下，提供高性能的深度学习模型。用户友好的 API 使得即使是初学者也能轻松入门，支持的数据类型包括图像、文本和表格数据。 这些 AutoML 框架各具特色，它们为不同的应用场景和需求提供了多种选择。无论是对于初学者，还是对于希望快速构建和部署机器学习模型的专业人士，这些框架都提供了强大的工具和功能。通过这些框架，用户可以更加便捷地利用机器学习技术，无需深入了解算法细节，就能够构建高效、准确的模型。 实验内容 了解了上面的准备知识后，接下来将展示如何依靠FLAML (Fast and Lightweight AutoML) 的全自动模式实现一个轻量级的电信诈骗号码的分类 （Classification） 问题。 (1) 加载数据和预处理 这里的数据来自通话记录明细的本地文件。 1234567891011121314import pandas as pdfrom sklearn.model_selection import train_test_split# 读取 Excel 文件，生成DataFrame，这里的Excel文件已经过添加标签处理df1 = pd.read_excel(&#x27;白名单用户通话明细.xlsx&#x27;)df2 = pd.read_excel(&#x27;黑名单用户通话明细0112.xlsx&#x27;)df3 = pd.read_excel(&#x27;黑名单用户通话明细0113.xlsx&#x27;)# 合并DataFramedf_combined = pd.concat([df1, df2, df3])# 确保索引有序，重置合并后DataFrame的索引df_combined = df_combined.reset_index(drop=True)# 显示合并后的DataFrame的前几行以确认print(df_combined.head()) 12345678# 首先，分离特征和目标变量X = df_combined.drop(&#x27;value&#x27;, axis=1) # 特征y = df_combined[&#x27;value&#x27;] # 目标变量# 分割数据集X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)X_train 从运行结果可以看到训练集测试集及标签的维度信息。 (2) 运行 FLAML 全自动模式 下面我们直接运行 FLAML automl 全自动模式。 实际在运行配置中，我们只需要可以指定 任务类型、时间预算、误差度量、学习者列表、是否下采样、重采样策略类型等。 如果不作任何设定的话，所有这些参数都会使用默认值(例如，默认分类器是 lgbm, xgboost, xgb_limitdepth, catboost, rf, extra_tree, lrl1)。 12# 导入工具库并初始化AutoML对象 from flaml import AutoML automl = AutoML() 12345678# 参数设定settings = &#123; &quot;time_budget&quot;: 600, # 指总共的运行时间 &quot;metric&quot;: &#x27;accuracy&#x27;, # 指衡量性能的标准，详见文档 &quot;task&quot;: &#x27;classification&#x27;, # 任务类型 &quot;log_file_name&quot;: &#x27;telefraud_experiment.log&#x27;, # 训练过程中日志文件命名 &quot;seed&quot;: 7654321, # 随机种子&#125; 12# 运行自动化机器学习 automl.fit(X_train=X_train, y_train=y_train, **settings) 从上述运行结果可以看出，自动机器学习过程，对 lgbm, xgboost, xgb_limitdepth, catboost, rf, extra_tree, lrl1 这些候选模型进行了实验，并运行出了对应的结果。 (3) 最优模型与评估结果 1234print(&#x27;Best ML leaner:&#x27;, automl.best_estimator) print(&#x27;Best hyperparmeter config:&#x27;, automl.best_config) print(&#x27;Best accuracy on validation data: &#123;0:.4g&#125;&#x27;.format(1-automl.best_loss)) print(&#x27;Training duration of best run: &#123;0:.4g&#125; s&#x27;.format(automl.best_config_train_time)) 运行结果如下 1234Best ML leaner: lgbmBest hyperparmeter config: &#123;&#x27;n_estimators&#x27;: 30, &#x27;num_leaves&#x27;: 153, &#x27;min_child_samples&#x27;: 13, &#x27;learning_rate&#x27;: 0.5373247775471219, &#x27;log_max_bin&#x27;: 7, &#x27;colsample_bytree&#x27;: 0.8846477664073648, &#x27;reg_alpha&#x27;: 0.001264139323090345, &#x27;reg_lambda&#x27;: 16.718685131056866&#125;Best accuracy on validation data: 0.9998Training duration of best run: 0.4925 s 可以通过运行完毕的 automl 对象属性，取出对应的「最优模型」、「最佳模型配置」、「评估准则结果」等信息。 更进一步，我们可以通过下面的代码，导出最优模型，并用它对测试集进行预测。 12# 最佳模型导出automl.model.estimator 运行结果如下 123456LGBMClassifier(colsample_bytree=0.8846477664073648, learning_rate=0.5373247775471219, max_bin=127, min_child_samples=13, n_estimators=1, n_jobs=-1, num_leaves=153, reg_alpha=0.001264139323090345, reg_lambda=16.718685131056866, verbose=-1) (4) 模型存储与加载 1234567# 模型存储与持久化import pickle with open(&#x27;automl.pkl&#x27;, &#x27;wb&#x27;) as f: pickle.dump(automl, f, pickle.HIGHEST_PROTOCOL) # 模型加载 with open(&#x27;automl.pkl&#x27;, &#x27;rb&#x27;) as f: automl = pickle.load(f) 123456# 对测试集进行预估y_pred = automl.predict(X_test) print(&#x27;Predicted labels&#x27;, y_pred) print(&#x27;True labels&#x27;, y_test) y_pred_proba = automl.predict_proba(X_test)[:,1] 运行结果如下： 12345678910111213Predicted labels [1. 1. 1. ... 1. 1. 1.]True labels 1263 1.03951 1.06199 1.06080 1.096 0.0 ... 3954 1.01840 1.04850 1.05208 1.02582 1.0Name: value, Length: 1303, dtype: float64 可以看到，automl 得到的最佳模型，对测试集预估的方式，和自己建模得到的模型是一样的。 12345# 测试集效果评估 from flaml.ml import sklearn_metric_loss_score print(&#x27;accuracy&#x27;, &#x27;=&#x27;, 1 - sklearn_metric_loss_score(&#x27;accuracy&#x27;, y_pred, y_test)) print(&#x27;roc_auc&#x27;, &#x27;=&#x27;, 1 - sklearn_metric_loss_score(&#x27;roc_auc&#x27;, y_pred_proba, y_test)) print(&#x27;log_loss&#x27;, &#x27;=&#x27;, sklearn_metric_loss_score(&#x27;log_loss&#x27;, y_pred_proba, y_test)) 评估结果如下： 123accuracy = 0.9720332824110467 roc_auc = 0.7253276908529442 log_loss = 0.1034449031876942 从评估结果中可以看出，该模型可以较好的完成号码识别的任务。 总结与展望 同样是一些无关轻重的文字*","categories":[],"tags":[{"name":"AutoML","slug":"AutoML","permalink":"https://2incccc.github.io/tags/AutoML/"},{"name":"自动机器学习","slug":"自动机器学习","permalink":"https://2incccc.github.io/tags/%E8%87%AA%E5%8A%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"AI4AI","slug":"AI4AI","permalink":"https://2incccc.github.io/tags/AI4AI/"}]},{"title":"ARM指令系统与编程","slug":"【微机原理与接口技术】 ARM指令系统与编程","date":"2023-12-24T17:25:00.000Z","updated":"2025-01-27T07:13:44.062Z","comments":true,"path":"2023/12/25/【微机原理与接口技术】 ARM指令系统与编程/","link":"","permalink":"https://2incccc.github.io/2023/12/25/%E3%80%90%E5%BE%AE%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A5%E5%8F%A3%E6%8A%80%E6%9C%AF%E3%80%91%20ARM%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F%E4%B8%8E%E7%BC%96%E7%A8%8B/","excerpt":"","text":"CPU 识别并执行的指令是由0、1二进制数组成的一串二进制码。可以让计算机执行某种操作的命令，称为机器指令。计算机的指令系统是指该计算机的 CPU 所能识别和执行的全部指令的集合。ARM 微处理器的低功耗、高性能特性主要归功于其高效的指令集架构 ISA。本章重点讲述 ARMv7架构的指令系统，包括 ARM 指令的指令格式、条件码、ARM 指令的寻址方式和 ARMv7架构下的 Thumb–2指令集。 3.1 ARM 指令系统简介 ARM 开发工具中新支持的统一汇编语言 UAL（unified assembly language）统一了 ARM 指令集和 Thumb 指令 3.1.2 指令格式 指令的格式由表示操作性质的操作码和表示操作对象的操作数两部分组成。 指令基本格式及示例 123&lt;opcode&gt;&#123;&lt;cond&gt;&#125;&#123;S&#125; &lt;Rd&gt;,&lt;Rn&gt;&#123;,&lt;shifter_operand&gt;&#125; MOVS R1, R2 ; MOV R1, R2 ; 条件码（cond） 第二源操作数（shifter_operand） 立即数方式（ #immend） 对于 32 位 ARM 指令，留给第二操作数立即数的只有 12 位，为了利用这 12 位来表示一个 32 位的立即数，可以将该立即数的空间分为两段：一段为 8 位的立即数（immend_8） 另一端 4 位为循环移位的位数（rotate_imm） 32 位立即数=immend_8 循环右移（2*rotate_imm 位） （为避免数据在首尾被分开，具体编码规则如下表） 寄存器方式 寄存器移位方式 3.2 ARM 指令的寻址方式 3.2.1 立即寻址 操作数直接放在指令中，例如 3.2.2 寄存器直接寻址 是各类寄存器中通常采用的一种执行效率较高的寻址方式 3.2.3 寄存器一位寻址 1AND R0, R1, R2, LSL#2 ; 3.2.4 寄存器间接寻址 寄存器中存放的内容是操作数的内存地址，用中括号括起来 3.2.4 基址变址寻址 某个寄存器提供一个基准地址，通过将该基准地址与指令中给出的“地址偏移量”相加，形成有效地址 3.2.6 多寄存器直接寻址 LDM（加载多个寄存器）和 STM（存储多个寄存器），实现一个指令完成多个通用寄存器的传送 3.2.7 堆栈寻址 3.3 ARM 核心指令 3.3.1 数据传送指令 寄存器间传送数据 寄存器合特殊功能寄存器传送数据 把一个立即数加在到寄存器 核心：MOV 3.3.2 存储器访问指令 1. 单寄存器加载和存储指令 2. 自动索引 3. 前索引 1LDR R0, [R1,#20]! ; 步骤 1：R0&lt;- [ R1+20 ] 步骤 2：R1=R1+20sd 4. 后索引 3.3.3 算术运算 ADD R16, R17, R18: 将寄存器R17和R18中的值相加，并将结果存储在R16中。 SUB R19, R20, #3: 从寄存器R20中减去立即数3，并将结果存储在R19中。 MUL R21, R22, R23: 将寄存器R22和R23中的值相乘，并将结果存储在R21中。 SDIV R24, R25, R26: 将寄存器R25中的值除以R26中的值，并将结果存储在R24中。 RSB R27, R28, #7: 将立即数7减去寄存器R28中的值，并将结果存储在R27中。 3.3.4 逻辑运算 AND R29, R30, #0x0F: 对寄存器R30的值和0x0F进行逻辑与操作，并将结果存储在R29中。 EOR R31, R32, #0x55: 对寄存器R32的值和0x55进行异或操作，并将结果存储在R31中。 BIC R33, R34, #0x80: 对寄存器R34的值和0x80进行位清零操作，并将结果存储在R33中。 ORR R35, R36, R37: 对寄存器R36和R37中的值进行逻辑或操作，并将结果存储在R35中。 MVN R38, R39: 对寄存器R39的值进行按位取反操作，并将结果存储在R38中。 3.3.5 移位和循环指令 ROR R40, R41, #1: 将寄存器R41的值向右旋转1位，并将结果存储在R40中。 RRX R42, R43: 将寄存器R43的值右移1位，同时将旧的标志位放入R42。 LSL R44, R45, R46: 将寄存器R45的值左移R46中的位数，并将结果存储在R44中。 ASR R47, R48, R49: 对寄存器R48的值进行算术右移R49中的位数，并将结果存储在R47中。 3.3.6 符号扩展 SXTH R50, R51: 将寄存器R51中的16位半字符号扩展为32位，并将结果存储在R50中。 SXTB R52, R53: 将寄存器R53中的8位字节符号扩展为32位，并将结果存储在R52中。 UXTB R54, R55: 将寄存器R55中的8位无符号字节扩展为32位，并将结果存储在R54中。 3.3.7 字节调序 REV R56, R57: 反转寄存器R57中的字节顺序，并将结果存储在R56中。 REV16 R58, R59: 反转寄存器R59中的16位数据的顺序，并将结果存储在R58中。 REVSH R60, R61: 反转寄存器R61中的16位数据的顺序，同时进行符号扩展，并将结果存储在R60中。 3.3.8 位域处理 BFI R62, R63, #3, #5: 将寄存器R63中的5位数据插入到寄存器R62的位域中，从第3位开始。 BFC R64, #8, #4: 将寄存器R64的位域从第8位开始清零，清零的位数为4。 3.3.9 子程序调整和无条件转移 BL Label1: 无条件分支到一个标签（子程序Label1），并将返回地址存储在链接寄存器中，用于后续的返回。 BX LR: 通过链接寄存器返回到子程序调用的地址。&gt;) 4.1 汇编语言程序 4.1.1 格式 1234N EQU 10 ; 定义常量N10Stack_Size EQU 0x00000400; 定义栈空间大小 AREA MyStack, NOINIT, READWRITE, ALIGN=3; 声明栈段Stack_Mem SPACE Stack_Size ;分配内存空间 常用的汇编指示命令 数据常量定义 1名称 EQU 表达式&#123;,类型&#125; 数据常量定义 123456789GBLA Test1 ; 定义一个全局数字变量，初始化0GBLL Test2 ; 定义一个全局逻辑变量，初始化FGBLS Test3 ; 定义全局字符串变量LCLA(L/S) Test4 ; 定义局部变量SETA(L/S) Test5 ; 重新赋值已定义的变量RegList RLIST &#123;R0-R5,R8,R10&#125; ; 将寄存器列表名称定义为RegList 内存分配 汇编控制汇编指示命令 12345IF 逻辑表达式 指令序列1ELSE 指令序列2ENDIF 123WHILE 逻辑表达式 指令序列WEND 其他常用汇编指令","categories":[{"name":"微机原理与接口技术","slug":"微机原理与接口技术","permalink":"https://2incccc.github.io/categories/%E5%BE%AE%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A5%E5%8F%A3%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://2incccc.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"ARM","slug":"ARM","permalink":"https://2incccc.github.io/tags/ARM/"},{"name":"微机原理","slug":"微机原理","permalink":"https://2incccc.github.io/tags/%E5%BE%AE%E6%9C%BA%E5%8E%9F%E7%90%86/"}]},{"title":"视频原理","slug":"【数字音视频原理】视频原理","date":"2023-12-11T17:26:38.000Z","updated":"2025-01-27T07:13:44.062Z","comments":true,"path":"2023/12/12/【数字音视频原理】视频原理/","link":"","permalink":"https://2incccc.github.io/2023/12/12/%E3%80%90%E6%95%B0%E5%AD%97%E9%9F%B3%E8%A7%86%E9%A2%91%E5%8E%9F%E7%90%86%E3%80%91%E8%A7%86%E9%A2%91%E5%8E%9F%E7%90%86/","excerpt":"","text":"模拟视频基础 图像扫描 扫描：将图像编程顺序传送的电信号的过程，从左至右（行扫描）、从上至下（帧扫描?） 如何选择行频、帧频（场频）和行数 帧频：有连续感-无闪烁感：20-45.8Hz 行数：Z=620 行频 带宽：考虑扫描两个像素的时间的倒数，即为最高频率（带宽） 隔行扫描 减少传输带宽，每次扫描提供 1/2 的行数，每帧被分为两场（奇数/偶数） 优势：减少闪烁、降低传输带宽 缺点：行间闪烁、视在并行、图像边缘锯齿化等等 分解力 显示设备所能分辨的图像像素数目、客观指标。 视觉特性要求电视系统垂直和水平方向上所能分解的像素尺寸相同。 视频信号带宽 视频信号的带宽主要由扫描行数 Z 和帧频 fF 决定的,在行数 Z 一定时,可以改变 fF 而达到降低 Δf 的目的。 基带信号 兼容彩色电视系统 传输三基色：YUV 实现在黑白和彩色电视系统中均能正确传送演示 数字视频取样 数字化基础 三个步骤：采样、量化、编码 数字分量视频:ITU-R 601 标准 信号彩色空间转换 由 RGB-&gt;Y(R-Y)(B-Y)-&gt;YC_BC_R 采用 8bit 量化 取样频率 子取样格式 数字视频压缩技术 压缩方法：无失真（2-5 倍）有失真压缩（5-250 倍） 无失真方法：游程数据编码和变字长编码 有失真方法：量化、变化编码、DPCM 编码、运动估计和补偿 图像的相关性（冗余度） 空间冗余：相邻像素之间的相关性 时间冗余：前后帧的相似性 信息熵冗余 时间 X 的概率为 P(X) 信息量定义为 信息熵是对所有可能时间的信息量进行平均 码的冗余定义： 图像压缩编码 熵编码 无损编码、针对信息熵冗余 变字长编码原理：如果码字长度严格按照符号概率大小的相反顺序，得到的平均码字长度一定是最小的 Huffman 编码 合并：按照概率大小顺序排列，每次将概率最小的概率相加 置换：将合并吼的看成是一个新符号的概率 类推：重复上述做法，直到剩下两个符号概率 幅值和反推，每个分支分别赋 1,0 （可以概率大的赋 1，概率小的赋 0） 编码效率=信息熵/编码后平均长度 Huffman 码特点 三大缺点 码率变化，（变字场） 均匀分布的概率模型效率低 概率模型是可以变化的 两个优点 时间短 非歧义 算术编码 也是对概率大的符号赋予短码，但是编码过程和 Huffman 编码不同，且在信源概率分布均匀情况下编码效率更高。 Huffman 码是用整数长度的码字来编码的最佳方法,而算法编码是一种并不局限于整数长度码字的最佳编码方法。 原理：使用二进制，考虑累积概率。算法编码产生的码字实际上是一个二进制数值的指针，指向所编符号对应的概率区间(约定指向左端点) 编码基本法则 两个参量：编码点 C 和区间宽度 A 新原原区间新区间原区间 解码基本法则 采取和编码相反的步骤 从第一个区间开始，寻找字符串指向的子区间，得到第一个符号 减去原编码点除以区间宽度，得到新码字符串 之后符号以此类推 二进制算数编码 输入字符只有两种，如果信源字符集含有多个字符，先经过一些列二进判决，变成二进制字符串。和算术编码原理类似，不断划分概率子区间的递归过程 编码输出可以是最后一个编码区间中的任意数值，选择最短的比特长度。但是截断需要提供编码次数 率失真 率失真理论旨在寻求一种联系定长编码的失真度与编码数据率的方法。","categories":[{"name":"数字音视频原理","slug":"数字音视频原理","permalink":"https://2incccc.github.io/categories/%E6%95%B0%E5%AD%97%E9%9F%B3%E8%A7%86%E9%A2%91%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"数字音视频","slug":"数字音视频","permalink":"https://2incccc.github.io/tags/%E6%95%B0%E5%AD%97%E9%9F%B3%E8%A7%86%E9%A2%91/"},{"name":"笔记","slug":"笔记","permalink":"https://2incccc.github.io/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"【MIR】Rhythm, Tempo, and Beat Tracking","slug":"【MIR】Rhythm, Tempo, and Beat Tracking","date":"2023-10-26T10:45:56.000Z","updated":"2025-01-27T07:13:44.060Z","comments":true,"path":"2023/10/26/【MIR】Rhythm, Tempo, and Beat Tracking/","link":"","permalink":"https://2incccc.github.io/2023/10/26/%E3%80%90MIR%E3%80%91Rhythm,%20Tempo,%20and%20Beat%20Tracking/","excerpt":"涵盖了关于节奏、节拍和音符起始点（onset）检测的关键概念和技术。","text":"Novelty Function 为了检测音符的开始，我们希望定位信号瞬态区域开始的突然变化，但是考虑到音高的变化不仅仅涉及响度的变化，也可能只涉及频率的改编（比如小提琴的演奏），所以，接下来我们介绍基于能量和基于频谱的 Novelty Function Energy-based Novelty Functions 通过均方根能量计算 主要涉及到的步骤：直接计算 RMSE 能量、求取 RMSE 的变化量（体现能量变化），对 delta RMSE 做半波整流，只保留能量增加部分 12345678910111213141516# 直接计算 RMSE 能量y_rms =librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length).flatten() # 计算差分rmse_diff = numpy.zeros_like(rmse)rmse_diff[1:] = numpy.diff(rmse) # 半波整流energy_novelty = numpy.max([numpy.zeros_like(rmse_diff), rmse_diff], axis=0) # 输出图像并比较plt.figure(figsize=(15, 6))plt.plot(t, rmse, &#x27;b--&#x27;, t, rmse_diff, &#x27;g--^&#x27;, t, energy_novelty, &#x27;r-&#x27;)plt.xlim(0, t.max())plt.xlabel(&#x27;Time (sec)&#x27;)plt.legend((&#x27;RMSE&#x27;, &#x27;delta RMSE&#x27;, &#x27;energy novelty&#x27;)) 对数能量 人类对声音强度的感知本质上是对数的。为了解释这一性质，我们可以在进行一阶差分之前对能量应用对数函数。 1log_rmse = numpy.log1p(10*rmse) 其余过程同上 Spectrum-based Novelty Functions 1spectral_novelty = librosa.onset.onset_strength(y=x, sr=sr) # 使用谱通量计算新奇函数 具体来说，librosa.onset.onset_strength 函数使用一种称为&quot;onset strength&quot; 的算法来计算这个信号。这个算法的目标是识别出音频信号中的突出事件，通常与音符、鼓击或其他音乐性事件的开始时刻相关 Peak computing 峰值计算 123456789101112def peak_pick(x, pre_max, post_max, pre_avg, post_avg, delta, wait): &#x27;&#x27;&#x27;Uses a flexible heuristic to pick peaks in a signal. A sample n is selected as a peak if the corresponding x[n] fulfills the following three conditions: 1. `x[n] == max(x[n - pre_max:n + post_max])` 2. `x[n] &gt;= mean(x[n - pre_avg:n + post_avg]) + delta` 3. `n - previous_n &gt; wait` where `previous_n` is the last sample picked as a peak (greedily). &#x27;&#x27;&#x27; 这是一个用于在信号中选择峰值（peaks）的函数，它采用了一种灵活的启发式方法。函数根据给定的条件选择信号中的峰值，这些条件旨在确保所选峰值具有一定的显著性和特定的时间间隔。让我解释每个条件的含义： x[n] == max(x[n - pre_max:n + post_max])：这表示在信号 x 中，一个样本 n 被选为峰值，如果它等于在前 pre_max 个样本和后 post_max 个样本范围内的样本中的最大值。这确保了所选的峰值是局部最大值。 x[n] &gt;= mean(x[n - pre_avg:n + post_avg]) + delta：这表示在信号 x 中，一个样本 n 被选为峰值，如果它的值大于或等于在前 pre_avg 个样本和后 post_avg 个样本范围内的样本的平均值再加上 delta。这个条件确保了所选的峰值比周围的平均值要显著。 n - previous_n &gt; wait：这个条件用于确保两个峰值之间有足够的时间间隔。 n 表示当前样本，previous_n 表示前一个已选择的峰值的样本。这个条件要求两个峰值之间的时间间隔至少为 wait 个样本。 因此，这个函数根据以上三个条件来选择信号中的峰值。这种方法可以用于从信号中提取出显著的峰值，例如，用于检测音频信号中的音符开始或其他信号中的突出事件。这种方法是一种启发式方法，可以根据应用的需求进行调整。 Onset detection (原理和上面类似) 12onset_frames = librosa.onset.onset_detect(y=x, sr=sr, wait=1, pre_avg=1, post_avg=1, pre_max=1, post_max=1)print(onset_frames) # frame numbers of estimated onsets 1[output]:[ 20 29 38 57 65 75 84 93 103 112 121 131 140 148 158 167 176 185 204 213 232 241 250 260 268 278 288] librosa.onset.onset_strength 和 librosa.onset.onset_detect 都是 Librosa 库中用于检测音频信号中的音符开始和强度的函数，但它们的功能和使用方式有一些不同。 librosa.onset.onset_strength: 功能：该函数计算音频信号的&quot;onset strength&quot; 或 “onset envelope”，即在时间上表示音频信号中的突出事件的信号。这个信号通常用于后续的音频事件检测。 参数：通常需要传递音频信号 y 和采样率 sr 作为参数，还可以提供其他参数来调整计算过程，例如 hop_length 和 aggregate. 返回值：函数返回一个代表音频信号强度的一维数组。 librosa.onset.onset_detect: 功能：这个函数使用 librosa.onset.onset_strength 的输出（或其他类似的音频强度信号）来检测音符开始或音频事件的时刻。它通过分析 “onset strength” 信号来查找潜在的音符开始时刻，并返回这些时刻的帧索引或时间。 参数：通常需要传递音频强度信号（如通过 librosa.onset.onset_strength 计算得到的）作为参数，以及一些其他参数，如 hop_length、backtrack 等，来调整检测过程。 返回值：函数返回一个包含音符开始时刻的帧索引或时间的一维数组。 总的来说，librosa.onset.onset_strength 用于计算音频信号的强度信号，而 librosa.onset.onset_detect 用于在强度信号上检测音符开始或音频事件的时刻。通常，它们一起使用，首先计算强度信号，然后使用 librosa.onset.onset_detect 来找到音符开始时刻。这种分离的方式允许更大的灵活性，因为您可以尝试不同的参数和强度信号来适应不同的音频分析任务。 Onset detection with backtracking 在很多情况中，考虑到音符改变不是瞬时完成，信号能量从平稳到峰值是有一个过程的，为避免检测 onset 时将 onset 从峰值切开，我们令参数 backtrack = True，实现对前面局部最值的回溯，可以确保能量变化的完整记录。 1onset_frames = librosa.onset.onset_detect(y=x, sr=sr, hop_length=hop_length, backtrack=True)","categories":[{"name":"Music Information Retrieval","slug":"Music-Information-Retrieval","permalink":"https://2incccc.github.io/categories/Music-Information-Retrieval/"}],"tags":[{"name":"音乐信息检索","slug":"音乐信息检索","permalink":"https://2incccc.github.io/tags/%E9%9F%B3%E4%B9%90%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2/"}]},{"title":"【MIR】Signal Analysis and Feature Extraction","slug":"【MIR】Signal Analysis and Reature Extraction","date":"2023-10-20T02:49:57.000Z","updated":"2025-01-27T07:13:44.060Z","comments":true,"path":"2023/10/20/【MIR】Signal Analysis and Reature Extraction/","link":"","permalink":"https://2incccc.github.io/2023/10/20/%E3%80%90MIR%E3%80%91Signal%20Analysis%20and%20Reature%20Extraction/","excerpt":"对音频信号的分析及相关特征提取","text":"基本特征提取 12345678910# 绘制波形librosa.display.waveshow([x[:1000]])# 特征提取：过零率/质心def extract_features(signal): stft_signal = librosa.core.stft(signal) magnitude = numpy.abs(stft_signal) return [ librosa.feature.zero_crossing_rate(signal)[0,0] librosa.feature.spectral_centroid(S=magnitude)[0,0] ] 零交叉率（Zero Crossing Rate）：零交叉率是一个表示信号快速变化的特征。它指的是信号波形穿过零轴的次数。在这段代码中，通过 librosa.feature.zero_crossing_rate(signal) [0, 0]来计算音频信号的零交叉率，并将结果作为特征之一返回。 频谱质心（Spectral Centroid）：频谱质心是频谱能量的加权平均值，用于表示音频信号的频谱中心。频谱质心越高，表示频谱的能量集中在较高的频率上，反之亦然。在这段代码中，通过 librosa.feature.spectral_centroid(S=magnitude) [0, 0]来计算音频信号的频谱质心，并将结果作为特征之一返回。 Feature Scaling 特征缩放 我们在上一个示例中使用的特征包括过零率和谱质心。这两个特征使用不同的单位来表示。这种差异可能会在稍后执行分类时带来问题。因此，我们将每个特征向量归一化到一个公共范围，并存储归一化参数以供以后使用。存在许多用于扩展功能的技术。现在，我们将使用[sklearn.preprocessing.MinMaxScaler]( http://scikit-learn.org/stable/modules/ generated/sklearn.preprocessing.MinMaxScaler.html)。 MinMaxScaler 返回一个缩放值数组，使得每个特征维度都在 -1 到 1 的范围内。 12345feature_table = numpy.vstack((kick_features, snare_features))scaler = sklearn.preprocessing.MinmaxScaler(feature_range=(-1,1)) # 定义一个范围在-1到1的预处理器training_features = scaler.fit_transform(feature_table) Segmantation 分割 在音频处理中，通常使用恒定的帧大小和跳跃大小（即增量）一次对一帧进行操作。帧的持续时间通常选择为 10 到 100 毫秒。 Segmentation Using Python List Comprehensions 在 Python 中，您可以使用标准的列表理解（https://docs.python.org/2/tutorial/datastructs.html#list-com经理）来执行信号分割并同时计算 RMSE。 123456# 定义帧长和间隔frame_length = 1024hop_length = 512# 均方根def RMSE(x): return numpy.sqrt(numpy.mean(x**2)) 给定一个信号，[librosa.util.frame]( https://librosa.github.io/librosa/ generated/librosa.util.frame.html #librosa .util.frame)将生成一个统一大小的帧列表: 1frames = librosa.util.frame(x, frame_length=frame_length, hop_length=hop_length) Energy 能量 信号的能量（[Wikipedia]( https://en.wikipedia.org/wiki/Energy_ (signal_processing%29); FMP, p. 66）对应于信号的总幅度。对于音频信号，大致对应于信号的响度。信号中的能量定义为 $$ \\sum_n \\left| x(n) \\right|^2 $$ The root-mean-square energy (RMSE) in a signal is defined as $$ \\sqrt{ \\frac{1}{N} \\sum_n \\left| x(n) \\right|^2 } $$ 123456789# 按照定义energy = numpy.array([ sum(abs(x[i:i+frame_length]**2)) for i in range(0, len(x), hop_length)])# 利用librosa函数rmse = librosa.feature.rmse(x, frame_length=frame_length, hop_length=hop_length, center=True) # shape(1,194)rmse = rmse[0] 1234567# 比较波形图和均方根能量frames = range(len(energy))t = librosa.frames_to_time(frames, sr=sr, hop_length=hop_length)librosa.display.waveshow(x, sr=sr, alpha=0.4)plt.plot(t, energy/energy.max(), &#x27;r--&#x27;) # normalized for visualizationplt.plot(t[:len(rmse)], rmse/rmse.max(), color=&#x27;g&#x27;) # normalized for visualizationplt.legend((&#x27;Energy&#x27;, &#x27;RMSE&#x27;)) Zero Crossing Rate 过零率 过零率指代信号波形穿过零轴的次数 12345678910n0 = 6500n1 = 7500plt.figure(figsize=(14, 5))plt.plot(x[n0:n1]) # zoom inzero_crossings = librosa.zero_crossings(x[n0:n1], pad=False) # 是否经过零点，输出结果为False和True的组合zeor_crossings.shape # output: (1000,0)zcrs = librosa.feature.zero_crossing_rate(x) # 过零率print(zcrs.shape) # output: (1,97) 过零率的高低与信号波形的特性有关。以下是一些常见的情况： 浊音/有谐波声音：浊音指的是声音中含有频谱中的多个谐波分量，通常听起来比较富有音色。浊音的过零率较低，因为在谐波声音中，波形会频繁穿过零线。 清音/无谐波声音：清音指的是声音中几乎没有谐波成分，通常听起来比较纯净。清音的过零率较高，因为在没有谐波的声音中，波形变化相对较平缓，不会频繁穿过零线。 静音：静音时，信号波形处于零线附近，过零率较高，因为信号在静音状态时频繁地从正值到负值或从负值到正值。 傅立叶变换 傅里叶变换(维基百科)是应用数学和信号处理中最基本的运算之一。 它将时域信号转换到频域。时域将信号表示为一系列采样，而频域将信号表示为不同幅度、频率和相位偏移的正弦波的叠加。 12345678910x,sr = librosa.load(&#x27;filename&#x27;) # 加载音频X = scipy.fft(x) # 求傅立叶变换X_mag = numpy.absolute(X) # 求模f = numpy.linspace(0, sr, len(X_mag)) # frequency variable 频率范围plt.figure(figsize=(13, 5))plt.plot(f, X_mag) # magnitude spectrumplt.xlabel(&#x27;Frequency (Hz)&#x27;) Short-Time Fourier Transform STFT 短时傅里叶变换 音乐信号是高度非平稳性的，也就是说，它们的统计数据会随着时间而变化。在一整首10分钟的歌曲中计算一次傅里叶变换是毫无意义的。 短时傅里叶变换(STFT)(维基百科;FMP，第 53 页)是通过计算信号中连续帧的傅里叶变换得到的。 $$ X(m, \\omega) = \\sum_n x(n) w(n-m) e^{-j \\omega n} $$ 当我们增加 $m$ 时，我们将窗口函数 $w$ 向右滑动。对于得到的坐标系，$x(n) w(n-m)$，我们计算傅里叶变换。因此，STFT $X$ 是时间 $m$ 和频率 $ω$ 的函数。 123hop_length = 512n_stft = 1024 # 设定STFT参数，包括帧长度和间隔X = librosa.stft(x, n_fft=n_fft, hop_length=hop_length) Spectrogram 谱图 在音乐处理中，我们通常只关心谱幅值而不关心相位含量。 谱图(维基百科;FMP(第 29、55 页)显示了频率随时间的强度。谱图就是 STFT 的平方幅度: $$ S(m, \\omega) = \\left| X(m, \\omega) \\right|^2 $$ 人类对声音强度的感知是基于对数（logarithmic）的，所以我们对对数幅度更感兴趣 123456S = librosa.amplitude_to_db(abs(X)) # 转化为对数plt.figure(figsize = (15,5))librosa.display.specshow(S, sr=sr, hop_length=hop_length, x_axis=&#x27;time&#x27;, y_axis=&#x27;linear&#x27;) # 使用specshow函数plt.colorbar(format=&#x27;%+2.0f dB&#x27;) Constant -Q Transform 常数 Q 变换 与傅立叶变换不同，但类似于 MEL 比例，常量 Q 变换(Wikipedia)使用对数间隔的频率轴。 Constant -Q Transform (CQT)是一种在频率上使用不同的频率分辨率来表示音频信号的方法，它模拟了人类听觉系统对不同音高的感知尺度。通过 CQT 变换，我们可以将音频信号转换为频谱表示，其中横轴表示时间，纵轴表示音高。 123fmin = librosa.midi_to_hz(36) # 设定最低频率C = librosa.cqt(x, sr=sr, fmin=fmin, n_bins=72) logC = librosa.amplitude_to_db(abs(C)) # 转换为对数谱 参数解释： fmin 是 CQT 变换的最低频率，表示变换时使用的最低音高。较低的 fmin 值将使 CQT 对低音更敏感。 n_bins 表示频率的总数量，它决定了 CQT 变换的音高范围和频率分辨率。N_bins 越大，音高范围越宽，频率分辨率越高。 Chroma (Chroma Vector) 色度向量(Wikipedia)(fmp，p.123)通常是12个元素的特征向量，指示信号中存在每个基音类别{C，C#，D，D#，E，…，B}的多少能量。 1234chromagram01 = librosa.feature.chroma_stft(y=x, sr=sr, hop_length=hop_length) # stft的色度向量 chromagram02 = librosa.feature.chroma_cqt(y=x, sr=sr, hop_length=hop_length) # cqt的色度向量plt.figure(figsize=(15, 5))librosa.display.specshow(chromagram, x_axis=&#x27;time&#x27;, y_axis=&#x27;chroma&#x27;, hop_length=hop_length, cmap=&#x27;coolwarm&#x27;) 输出结果： 色度能量归一化统计量(Chroma energy normalized statistics, CENS)。CENS 功能的主要思想是对大窗口进行统计，以平滑节奏、清晰度和音乐装饰(如颤音和弦)的局部偏差。CENS 最适合用于音频匹配和相似性等任务。librosa.feature.chroma_cens() Magnitude_scaling 振幅缩放（？） 通常，信号在时域或频域中的原始幅度与人类的感知相关性不如转换成其他单位的幅度，例如使用对数标度。 即使振幅呈指数增长，对我们来说，响度的增加似乎是渐进的。这种现象是 Weber-Fechner 定律(维基百科)的一个例子，该定律指出刺激和人类感知之间的关系是对数的。 Spectral Features 频谱特征 对于分类问题，我们将使用新的统计量矩（Moment）（包括质心、带宽、偏度、峰度）和其他谱统计数据。 矩（Moment）是物理学和统计学中出现的术语。矩的两个示例：均值和方差，第一个是原点矩，第二个是中心矩。 频谱质心 频谱质心（维基百科）指示频谱能量集中在哪个频率。这就像加权平均值： $$ f_c = \\frac{\\sum_k S(k) f(k)}{\\sum_k S(k)} $$ 其中 $S(k)$ 是频率 bin $ 处的频谱幅度 k$, $f(k)$ 是 bin $k$ 处的频率。 [librosa.Feature.Spectral_centroid]( https://librosa.github.io/librosa/ generated/librosa.Feature.Spectral_centroid.Html #librosa .feature.Spectral_centroid) 计算信号中每个帧的光谱质心. 输出图像： 与过零率类似，信号开始处的频谱质心存在虚假上升。这是因为开始时的静默幅度很小，高频成分有机会占主导地位。解决这个问题的一种方法是在计算光谱质心之前添加一个小常数，从而在安静部分将质心移向零。 频谱带宽 [librosa.feature.spectral_bandwidth]( https://librosa.github.io/librosa/ generated/librosa.feature.spectral_bandwidth.html #librosa .feature.spectral_bandwidth) 计算 $p$ 阶光谱带宽： $$ \\left( \\sum_k S(k) \\left(f(k) - f_c \\right)^p \\right)^{\\frac{1}{p}} $$ 其中 $S(k)$ 是在频率 $k$ 处的幅度，$f(k)$ 是 $k$ 处的频率，$f_c$ 是频谱质心。当 $p = 2$ 时，这就像加权标准差。 频谱对比度 考虑频谱峰值、谷值以及他们在每个频率子带中的差异。 [librosa.feature.spectral_contrast]( https://librosa.github.io/librosa/ generated/librosa.feature.spectral_contrast.html) 计算每个时间帧的六个子带的光谱对比度： 频谱滚降 是指低于总频谱能量指定百分比的频率 lirosa.feature.spectral_rolloff Autocorrelation 自相关 指代自身和时移后自身的相关性。对于信号 $x$，它的自相关信号 $r(k)$ 为 $$ r(k) = \\sum_n x(n) x(n-k) $$ 在此等式中，$k$ 通常称为 lag 参数。 $r(k)$ 在 $k = 0$ 处最大化，并且关于 $k$ 对称。 自相关对于查找信号中的重复模式很有用。例如，在短滞后时，自相关可以告诉我们有关信号基频的信息。对于较长的滞后，自相关可以告诉我们一些有关音乐信号节奏的信息。 两种计算 autororrelation 的方法：numpy.correlate 和 librosa.autocorrelation 音高估计 自相关用于查找信号内的重复模式。对于音乐信号，重复模式可以对应于音高周期。因此，我们可以使用自相关函数，通过寻找最值点来估计音乐信号中的音高。 Pitch Transcription Exercise 声调转录 在音频信号处理中，声调转录是指将音频中的音高信息转录成对应的音符或音高表示的过程。这个过程通常涉及到分析音频信号中的频率变化和音高轮廓，从而识别出其中的音符和音高变化。 准备工作： 导入库函数 1234%matpltlib inline # 将图像输出在notebook中而不是在新窗口import numpy, IPython.display as ipd, matpltlib.pyplot as pltimport librosa, librosa.displayplt.rcParams[&#x27;figure.figsize&#x27;] = (14, 5) 加载音频并播放 123filename = &#x27;../audio/simple_piano.wav&#x27;x,sr = librosa.load(filename)ipd.Audio(x,rate=sr) 计算 CQT 并输出频谱 12345bins_per_octave = 36 # 设置每个八度的频率间隔数目，表示频率轴分辨率cqt = librosa.cqt(x,sr=sr, n_bins=300, bins_per_octave = bins_per_octave) # 使用cqt函数log_cqt = librosa.amplitude_to_db(numpy.abs(cqt)) #转化对数谱librosa.display.specshow(log_cqt, sr=sr, x_axis=&#x27;time&#x27;, y_axis=&#x27;cqt_note&#x27;, bins_per_octave=36) 简单观察声谱图可知，整个音频大概包含八个相同或不同的音符，但是混杂在每一个音符的还有各种其他频率的分量。 任务目标 识别每个音符的音高，并将每个音符用相同音调的纯音（Pure Tone）组合起来代替音频 任务流程 第一步：检测起点 在音频信号处理和音乐分析中，“onset”（起点）是指音频信号中音乐或声音的开始部分，即音频信号开始出现显著能量变化的位置。换句话说，“onset” 表示音频信号中从无声到有声或从背景噪声到音乐开始的那个时间点。 在音频信号处理中，通常使用不同的算法和特征来检测 “onset”，比如短时能量、短时过零率、梅尔频率倒谱系数（MFCC）等。这些方法可以帮助准确地找到音频信号中显著的能量变化点，从而确定 “onset” 的位置。 在这里，我们使用新颖度函数（novelty function）来寻找音频信号中的起点。 1234hop_length = 100onset_env = librosa.onset.onset_strength(y=x, sr=sr, hop_length=hop_length)plt.plot(onset_env)plt.xlim(0,len(onset_env)) 在上图可以看到，除了几个比较显著的波峰，还有更多的很小的波峰，我们需要设置参数来忽略这些很小的波峰。 接下来使用 onset_detct 实现对起点的检测 1234567891011onset_samples = librosa.onset.onset_detect(y=x, sr=sr, units=&#x27;samples&#x27;, hop_length=hop_length, backtrack=False, pre_max=20, post_max=20, pre_avg=100, post_avg=100, delta=0.2, wait=0)print(onset_samples) 1output:[5800 11300 22300 33300 44300 55300 66400] 为了能将整个音频按照音符数分割开来，还要在序列首尾添加 padding 12onset_boundaries = numpy.concatenate([[0], onset_samples, [len(x)]])print(onset_boundaries) 1output:[0 5800 11300 22300 33300 44300 55300 66400 84928] 最后将采样点数转换为时间 12onset_times = librosa.samples_to_time(onset_boundaries,sr=sr)print(onset_times) 12output:array(array([ 0. , 0.26303855, 0.51247166, 1.01133787, 1.51020408,2.00907029, 2.50793651, 3.01133787, 3.85160998])) 最后将分割后的结果在频谱图中展示出来 12librosa.display.waveshow(x,sr=sr)plt.vlines(onset_times,-1,1,color=&#x27;r&#x27;) 经过上面的操作，我们可以看懂，红线将整个将音频中八个音符，对应波形中有明显不连续的地方分割开来。 第二步，估计音调 我们效仿前面的学习内容，使用自相关方法确定音高。 自相关用于查找信号内的重复模式。对于音乐信号，重复模式可以对应于音高周期。因此，我们可以使用自相关函数，通过寻找最值点来估计音乐信号中的音高 123456789101112131415def estimate_pitch(segment, sr, fmin=50.0, fmax=2000.0): # 计算输入的自相关 r = librosa.autocorrelate(segment) # 定义自相关最值点的范围 i_min = sr/fmax i_max = sr/fmin r[:int(i_min)] = 0 r[int(i_max):] = 0 # 寻找最值，返回对应频率 i = r.argmax() f0 = float(sr)/i return f0 第三步：生成纯音 Pure Tone 这里我们直接使用 numpy.sin 生成频率固定的正弦波纯音。 1234def generate_sine(f0, sr, n_duration): # 生成正弦波 n = numpy.arange(n_duration) return 0.2*numpy.sin(2*numpy.pi*f0*n/float(sr)) 第四步：将纯音组合起来 12345678910def estimate_pitch_and_generate_sine(x, onset_samples, i, sr): # 找到起点位置的频率，将每一音符分割开来 n0 = onset_samples[i] n1 = onset_samples[i+1] # 调用函数，估计每个音符的音高 f0 = estimate_pitch(x[n0:n1], sr) # 返回相同音高的纯音 return generate_sine(f0, sr, n1-n0) 接下来使用 numpy.concatenate 将合成的片段连接起来并演奏 12345y = numpy.concatenate([ estimate_pitch_and_generate_sine(x, onset_boundaries, i, sr=sr) for i in range(len(onset_boundaries)-1)])ipd.Audio(y,rate=sr) 为可视化展现合成后音频的最终结果，绘制合成后音频的 CQT 谱图 12cqt=librosa.cqt(y,sr=sr)librosa.display.specshow(abs(cqt),sr=sr,x_axis=&#x27;time&#x27;,y_axis=&#x27;cqt_mode&#x27;) 可以清晰看到，每个音符对应的频率谱图变得纯净，其他频率的分量基本完全消失。 至此，我们完成了这段音频的声调转录工作。","categories":[{"name":"Music Information Retrieval","slug":"Music-Information-Retrieval","permalink":"https://2incccc.github.io/categories/Music-Information-Retrieval/"}],"tags":[{"name":"音乐信息检索","slug":"音乐信息检索","permalink":"https://2incccc.github.io/tags/%E9%9F%B3%E4%B9%90%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2/"}]},{"title":"【数学建模】线性规划/整数规划/非线性规划","slug":"【数学建模】线性规划-整数规划-非线性规划","date":"2023-07-23T17:38:33.000Z","updated":"2025-01-27T07:13:44.062Z","comments":true,"path":"2023/07/24/【数学建模】线性规划-整数规划-非线性规划/","link":"","permalink":"https://2incccc.github.io/2023/07/24/%E3%80%90%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E3%80%91%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92-%E6%95%B4%E6%95%B0%E8%A7%84%E5%88%92-%E9%9D%9E%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92/","excerpt":"","text":"一、线性规划模型基本原理与案例分享 线性规划问题 在人们的生产实践中，经常会遇到如何利用现有资源来安排生产，以取得最大经济效益的问题。此类问题构成了运筹学的一个重要分支—数学规划，而 线性规划 (Linear Programming 简记 LP)则是数学规划的一个重要分支。 实例与定义 例1.1 某机床厂生产甲、乙两种机床，每合销售后的利润分别为4千元与3千元。生产甲机床需用 A、B 机器加工，加工时间分别为每合2小时和1小时； 生产乙机床需用 A、B、C 三种机器加工，加工时间为每合各一小时。若每天可用于加工的机器时 数分别为 A 机器10小时、B 机器8小时和 C 机器7小时，问该厂应生产甲、乙机床各几合，才能使总利润最大？ MATLAB 标准形式及软件求解 matlab 中标准形式： 其中 都是列向量 matlab 中求解线性规划的命令： 123[x,fval] = linprog(c,A,b)[x,fval] = linporg(c,A,b,Aeq,beq)[x,fval] = linprog(c,A,b,Aeq,beq,lb,ub) 其中 x 是返回决策向量的取值，fval 返回的是目标函数的最优值 示例：投资的收益和风险 二、整数规划基本原理与编程实践 整数规划模型（IP） 数学规划中的变量（部分或全部）限制为整数时，称为整数规划。若在线性规划模型中，变量限制为整数，则称为整数线性规划。目前所流行的求解整数规划的方法，往往只适用于整数线性规划。目前还没有一种方法能有效地求解一切整数规划。 整数规划特点 原线性规划有最优解，当自变量限制为整数后，其整数规划解出现下述情况 原线性规划最优解全是整数，则整数规划最优解与线性规划最优解一致 整数规划无可行解 有可行解（当然就存在最优解），但最优解值变差 整数规划最优解不能按照实数最优解简单取整而获得 求解方法 1. 图解法 直接枚举，研究约束条件内所有整数点 2. 分枝定界法 不考虑整数限制先求出相应松弛问题的最优解： 若松弛问题无可行解，则 LP 无可行解； 若求得的松弛问题最优解符合整数要求，则是 LP 的最优解； 若不满足整数条件，则任选一个不满足整数条件的变量 x 来构造新的约束添加到松弛问题中形成两个子问题，依次在缩小的可行域中求解新构造的线性规划的最优解，并重复上述过程， 3. 割平面法 如果(P0)的解含有非整数分量，则对(P0) 增加割平面条件：即对(P0)增加一个线性约束，将(P0)的可行区域割掉一块，使得非整数解恰好在割掉的一块中，但又没有割掉原问题§的可行解，得到问题(P1)，重复上述的过程。 4. 匈牙利算法（求解 0-1 规划） 0-1 规划： 变量只能取 0 或者 1，出现互斥约束 互斥约束的推广： M 取无穷大，使其小于无穷大（或大于无穷小） 特例：指派问题： 例：甲乙丙丁四个人，ABCD 四项工作，要求每人只能做一项工 作，每项工作只由一人完成，问如何指派总时间最短？ 标准形式：有 n 个人和 n 项工作，已知第 i 个人做第 j 项工作的代价 为 (i,j=1,…,n),要求每项工作只能交与其中一人完成，每个 人只能完成其中一项工作，问如何分配可使总代价最少？ 数学模型： 表示第 i 个人做第 j 项工作，或者表示代价/利润 非标准形式： 1. 最大化指派 2. 人数和工作数不等 3. 一个人可做多件工作 4. 工作一定不能由某人做 指派问题的匈牙利解法一般步骤 变换指派问题的系数(也称效率)矩阵(cij) 为(bij)，使在 (bij) 的各行各列中都出现==（至少个数的）==0元素，先每行减最小，再每列减最小==（寻找最小元素）（此时每行每列已至少出现一个 0）== 进行试指派寻找最优解 从只有一个 0 元素的行列开始，==圈出==该 0 元素，==划去==同行同列（十字）中其他的 0，（已为该元素分配任务，不参与其他分配），直到尽可能多的0元素都被圈出和划掉为止。 作最少直线覆盖所有 0 元素 变换矩阵增加 0 元素，==注意不能改变已有零元素==，减去已有的最小元素，改变行加上一个数要注意要改变列减去一个数 三、非线性规划基本原理与编程实践 非线性规划模型(NP) 如果目标函数或约束条件中包含非线性函数（二次、三次等），就称这种规划问题为非线 性规划问题。 MATLAB一般形式： 其中 f(x)是标量函数，A,b,Aeq,beq,lb,ub 是相应维数的 矩阵和向量，c(x),ceq(x)是非线性向量函数。 MATLAB 命令： 1[x,faval] = fmincon(fun,x0,A,b,Aeq,beq,lb,ub,nonlcon,options) fun 是用 M 文件定义的函数，x0是 x 的初始值；（==可以用 rand 函数定义==） nonlcon 是用 M 文件定义的非线性向量函数 c(x),ceq(x)；options 定义了优化参数，可以使用 Matlab 缺省的参数设置。 二次规划 目标函数为自变量的二次函数，而约束条件全是线性 数学表述","categories":[{"name":"数学建模教程","slug":"数学建模教程","permalink":"https://2incccc.github.io/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"数学建模","slug":"数学建模","permalink":"https://2incccc.github.io/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"},{"name":"规划，数学建模老哥","slug":"规划，数学建模老哥","permalink":"https://2incccc.github.io/tags/%E8%A7%84%E5%88%92%EF%BC%8C%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E8%80%81%E5%93%A5/"}]},{"title":"【深度学习教程】Chapter 4 神经网络训练","slug":"【音频信号处理及深度学习教程】Chapter 4 神经网络训练","date":"2023-07-14T17:23:05.000Z","updated":"2025-01-27T07:13:44.063Z","comments":true,"path":"2023/07/15/【音频信号处理及深度学习教程】Chapter 4 神经网络训练/","link":"","permalink":"https://2incccc.github.io/2023/07/15/%E3%80%90%E9%9F%B3%E9%A2%91%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E5%8F%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B%E3%80%91Chapter%204%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83/","excerpt":"Chapter 4 神经网络训练 神经网络训练 训练的过程是反向传播的过程，利用得到的输出值与预测值的偏差，（损失函数），反向更新模型中的参数 逼近的思路理解训练 随机生成一个三阶函数，赋予一组随机参数，得到的输出与 sine 输出值比较，差值 loss 最小的那一组参数就为目标函数。 流程： 根据预测值和标签值得到 loss Loss 函数对各个参数反向求偏导 计算每个参数的梯度 更新参数值 梯度置 0 再次循环","text":"Chapter 4 神经网络训练 神经网络训练 训练的过程是反向传播的过程，利用得到的输出值与预测值的偏差，（损失函数），反向更新模型中的参数 逼近的思路理解训练 随机生成一个三阶函数，赋予一组随机参数，得到的输出与 sine 输出值比较，差值 loss 最小的那一组参数就为目标函数。 流程： 根据预测值和标签值得到 loss Loss 函数对各个参数反向求偏导 计算每个参数的梯度 更新参数值 梯度置 0 再次循环 反向传播 高阶函数构造 sin(x) c 常规思路：loss 对各参数求偏导，计算梯度，更新梯度值，梯度置 0 12345678910111213141516171819202122232425262728293031323334353637&quot;&quot;&quot;用一个三阶函数找到合适的参数 逼近y=sinx# 1.构建三阶函数# 2.给定输入，得到该函数的输出值,共循环500次# 3.得到该函数的输出值与y=sinx的输出 偏差loss函数# 4.为了得到loss最小，求该函数的极小值（导数）# 5.根据梯度值，更新参数&quot;&quot;&quot;import numpy as np# 0.sinex = np.linspace(start=-np.pi,stop=np.pi,num=2000)y = np.sin(x)a,b,c,d = np.random.rand(),np.random.rand(),np.random.rand(),np.random.rand()learning_rate = 1e-6# 学习率（learning rate）用于控制参数更新的步长。它决定了每一步更新中参数的变化量。for epoch in range(200000): y_pred = a + b*x + c*x**2 + d*x**3 loss = np.square(y_pred - y).sum() grad_y_pre = 2 * (y_pred - y) grad_a = grad_y_pre.sum() grad_b = (grad_y_pre * x**1).sum() grad_c = (grad_y_pre * x**2).sum() grad_d = (grad_y_pre * x**3).sum() a -= learning_rate * grad_a b -= learning_rate * grad_b c -= learning_rate * grad_c d -= learning_rate * grad_d # 以上为求导过程 # 根据链式法则，损失函数关于b的偏导数可以表示为：∂loss/∂b = ∂loss/∂y_pred * ∂y_pred/∂b if epoch%20 == 0: # Epoch（时期）是指将整个训练数据集（dataset）通过神经网络进行前向传播和反向传播的一次完整迭代。 print(loss)print(f&quot;y_pred = &#123;a.item()&#125; + &#123;b.item()&#125;*x + &#123;c.item()&#125;*x^2 + &#123;d.item()&#125;*x^3&quot;) loss.backward():由该函数确定更新后的参数值 （这是一个 PyTorch 库中的函数，输入输出需要为张量） 123456789101112131415161718192021222324252627282930313233343536373839&quot;&quot;&quot;用一个三阶函数找到合适的参数 逼近y=sinx# 1.构建三阶函数# 2.给定输入，得到该函数的输出值,共循环500次# 3.得到该函数的输出值与y=sinx的输出 偏差loss函数# 4.为了得到loss最小，求该函数的极小值（导数）# 5.根据梯度值，更新参数&quot;&quot;&quot;import torch# 0.sinex = torch.linspace(start=-torch.pi,end=torch.pi,steps=2000)y = torch.sin(x)a,b,c,d = torch.rand((),requires_grad=True),torch.rand((),requires_grad=True),\\ torch.rand((),requires_grad=True),torch.rand((),requires_grad=True)learning_rate = 1e-6for epoch in range(2000): y_pred = a + b*x + c*x**2 + d*x**3 loss = torch.square((y_pred - y),).sum() debug = 1 loss.backward() # 使用该函数，代替求导的过程 with torch.no_grad(): a -= learning_rate * a.grad b -= learning_rate * b.grad c -= learning_rate * c.grad d -= learning_rate * d.grad a.grad = None b.grad = None c.grad = None d.grad = None debug = 1 if epoch%20 == 0: print(loss) print(f&quot;y_pred = &#123;a.item()&#125; + &#123;b.item()&#125;*x + &#123;c.item()&#125;*x^2 + &#123;d.item()&#125;*x^3&quot;) optimiser.step(): 优化器函数（同上） 123456789101112131415161718192021222324252627282930313233343536373839404142434445&quot;&quot;&quot;用一个网络模型 逼近y=sinx# 1.给定输入，得到sin的输出值为y# 2.给定输入，根据y=a+b*x+c*x**2+d*x**3,计算^1,^2,^3不同幂次下的结果# 3.构建网络模型，利用线性层将不同幂次下的结果按一定权重相加，包含线性层Linear(3,1),Flatten()# 4.将三个结果放入模型得到该函数的输出值,共循环500-&gt;2000次# 4.得到该函数的输出值与y=sinx的输出,偏差loss函数= torch.square(y_pre - y).sum()# 5.为了得到loss最小，求该函数的极小值（导数）loss.backward()# 6.根据梯度值，更新参数 param -= learning_rate * param.grad 之后 model.zero_grad()&quot;&quot;&quot;from torch import nnimport torchclass Liner(nn.Module): def __init__(self): super().__init__() self.model = nn.Sequential(nn.Linear(3,1),nn.Flatten(0,1)) def forward(self,data): output = self.model(data) return outputx = torch.linspace(-torch.pi,torch.pi,2_000)y = torch.sin(x)# x^1,x^2,x^3mynn = Liner()p = torch.tensor([1,2,3])input = x.unsqueeze(-1).pow(p)learning_rate = 1e-4optimiser = torch.optim.RMSprop(params=mynn.model.parameters(),lr=learning_rate)loss_fn = torch.nn.MSELoss() # 代替square平方求和for epoch in range(2_000): y_pre = mynn(input) loss = loss_fn(y_pre,y) layer_liner = mynn.model[0] layer_flatten = mynn.model[1] debug = 1 optimiser.zero_grad() # 用于将模型参数的梯度归零。 loss.backward() # 反向更新参数 optimiser.step() # 优化器，代替-=的过程 if epoch % 10==0: print(loss) debug = 1debug = 1 需要注意： optimiser = torch.optim.RMSprop(params=mynn.model.parameters(),lr=learning_rate) 定义了一个优化器，参数是模型中的各个参数，lr 是学习率。在机器学习和深度学习中，优化器（Optimizer）是一种用于调整模型参数以最小化损失函数的算法或方法。优化器根据模型的梯度信息和指定的优化算法，更新模型参数的值，以便使损失函数达到最小值或接近最小值。在训练神经网络模型的过程中，优化器的作用非常重要。它能够根据损失函数的梯度信息来更新模型参数，使得模型能够逐步调整自身以更好地拟合训练数据。 loss.Backward() 的任务是执行反向传播计算梯度。具体来说，它计算损失函数 loss 关于模型参数的梯度，通过使用链式法则将梯度从损失函数传播到模型的每个参数。这样可以获得每个参数相对于损失函数的梯度信息，即参数的更新方向和大小。 optimiser.step() 的任务是根据梯度信息更新模型参数的值。它使用优化算法（如 RMSprop）和学习率来计算参数的更新量，并将这个更新量应用到模型的参数上，从而更新参数的值。这样，模型的参数会朝着减小损失函数的方向进行调整。 损失函数与优化器 常用的损失函数 平方损失 输出-预期的平方的求和 最大似然处理，输出的结果（似然值）视为概率，再去求得到该结果概率值最大的权重系数 w。已知事情发生的结果，反推发生该结果概率最大的参数 w P(x|w,b) 交叉熵损失 1234567891011121314151617181920&quot;&quot;&quot;损失函数的使用# 1.定义两个变量# 2.损失函数选择L1Loss()，参量选择 均值与取和——(P1-E1)+(P2-E2)+...(PN-EN)/N# 3.损失函数选择MSELoss()——(P1-E1)^2+(P2-E2)^2+...(PN-EN)^2/N&quot;&quot;&quot;import torchfrom torch import nny_pred = torch.tensor([1,2,3],dtype=torch.float32)y = torch.tensor([1,2,5],dtype=torch.float32)# 2.损失函数选择L1Loss()，参量选择 均值与取和——(P1-E1)+(P2-E2)+...(PN-EN)/Nloss_l1 = torch.nn.L1Loss(reduction=&quot;sum&quot;)result1 = loss_l1(y_pred,y)print(result1)# 3.损失函数选择MSELoss()——(P1-E1)^2+(P2-E2)^2+...(PN-EN)^2/Nloss_mse = torch.nn.MSELoss(reduction=&quot;sum&quot;)result2 = loss_mse(y_pred,y)print(result2) 常用的优化器 SGD Adam 构建神经网络全过程 搭建+训练（Chapter 3+4） 下载数据-&gt;加载数据-&gt;准备模型-&gt;设置损失函数-&gt;设置优化器-&gt;开始训练-&gt;最后验证-&gt;结果聚合展示 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475from torch import nnimport torch# 1.搭建模型class Mynetwork(nn.Module): def __init__(self): super().__init__() self.model = nn.Sequential(nn.Conv2d(3,32,5,1,2),nn.MaxPool2d(2), nn.Conv2d(32,32,5,1,2),nn.MaxPool2d(2), nn.Conv2d(32,64,5,1,2),nn.MaxPool2d(2), nn.Flatten(),nn.Linear(64*4*4,64),nn.Linear(64,10)) # 包括卷积、池化、线性等等 def forward(self,data): # 前向驱动函数 output = self.model(data) return output# 2.得到数据集input = torch.ones(size=(1,3,32,32),dtype=torch.float32) # 数据集y = torch.tensor([[1,2,3,4,5,6,7,8,9,10]],dtype=torch.float32)# 3.调用模型得到输出mynn = Mynetwork()loss_fn = torch.nn.MSELoss(reduction=&quot;mean&quot;) # 损失函数optimiser = torch.optim.RMSprop(params=mynn.model.parameters(),lr=1e-4) # 定义优化器for period in range(100): print(f&quot;this is period &#123;period+1&#125;:&quot;) for data in range(1): y_pred = mynn(input) # 导入模型 # 4.计算真实值与输出值之间的偏差loss loss = loss_fn(y_pred,y) # 7.迭代一次后 梯度置零 optimiser.zero_grad() # 5.计算各参量的梯度值 loss.backward() # 6.用优化器更新参数 optimiser.step() if data % 10 ==0: print(loss)print(f&quot;The final outcome is &#123;y_pred&#125;&quot;)----------------------------------------------------# output：this is period 1:tensor(38.6425, grad_fn=&lt;MseLossBackward0&gt;)this is period 2:tensor(34.2981, grad_fn=&lt;MseLossBackward0&gt;)this is period 3:tensor(22.4355, grad_fn=&lt;MseLossBackward0&gt;)this is period 4:tensor(3.7360, grad_fn=&lt;MseLossBackward0&gt;)this is period 5:tensor(4.2519, grad_fn=&lt;MseLossBackward0&gt;)this is period 6:tensor(7.7438, grad_fn=&lt;MseLossBackward0&gt;)this is period 7:....tensor(0.1047, grad_fn=&lt;MseLossBackward0&gt;)this is period 96:tensor(0.1212, grad_fn=&lt;MseLossBackward0&gt;)this is period 97:tensor(0.0982, grad_fn=&lt;MseLossBackward0&gt;)this is period 98:tensor(0.1128, grad_fn=&lt;MseLossBackward0&gt;)this is period 99:tensor(0.0920, grad_fn=&lt;MseLossBackward0&gt;)this is period 100:tensor(0.1051, grad_fn=&lt;MseLossBackward0&gt;)The final outcome is tensor([[0.8946, 1.8333, 2.8251, 3.7509, 4.7626, 5.6981, 6.6488, 7.6014, 8.5054, 9.5048]], grad_fn=&lt;AddmmBackward0&gt;) Tensor(38.6425)：这部分表示损失函数的数值，即计算得到的具体损失值。在这个例子中，损失函数的值为 38.6425。 grad_fn=&lt;MseLossBackward0&gt;：这部分表示损失函数的计算图中的反向传播函数。它指示了该张量是通过执行反向传播操作计算得到的，并且在计算图中有一个与之相关的反向传播函数。在这个例子中，使用的是均方误差损失函数（MSELoss），因此显示为 &lt;MseLossBackward0&gt;。","categories":[{"name":"音频信号处理及深度学习教程","slug":"音频信号处理及深度学习教程","permalink":"https://2incccc.github.io/categories/%E9%9F%B3%E9%A2%91%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E5%8F%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://2incccc.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"音频信号","slug":"音频信号","permalink":"https://2incccc.github.io/tags/%E9%9F%B3%E9%A2%91%E4%BF%A1%E5%8F%B7/"},{"name":"声学","slug":"声学","permalink":"https://2incccc.github.io/tags/%E5%A3%B0%E5%AD%A6/"},{"name":"神经网络","slug":"神经网络","permalink":"https://2incccc.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"信号处理","slug":"信号处理","permalink":"https://2incccc.github.io/tags/%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/"},{"name":"人工智能","slug":"人工智能","permalink":"https://2incccc.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}]},{"title":"【大唐杯】5G网络架构与组网部署","slug":"【大唐杯】5G网络架构与组网部署","date":"2023-02-06T14:13:59.000Z","updated":"2025-01-27T07:13:44.066Z","comments":true,"path":"2023/02/06/【大唐杯】5G网络架构与组网部署/","link":"","permalink":"https://2incccc.github.io/2023/02/06/%E3%80%90%E5%A4%A7%E5%94%90%E6%9D%AF%E3%80%915G%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%BB%84%E7%BD%91%E9%83%A8%E7%BD%B2/","excerpt":"课程来源：第一章-5G网络架构与组网部署-01 课程目标 5G网络整体架构组成 主要网元功能 网元间接口关系 了解5G网络组网部署策略 目录 1.1 5G网络架构的演进趋势 1.2 5G网元功能与接口 1.3 5G网络组网部署 1.1 5G网络架构的演进趋势","text":"课程来源：第一章-5G网络架构与组网部署-01 课程目标 5G网络整体架构组成 主要网元功能 网元间接口关系 了解5G网络组网部署策略 目录 1.1 5G网络架构的演进趋势 1.2 5G网元功能与接口 1.3 5G网络组网部署 1.1 5G网络架构的演进趋势 概述 5G通信系统包括 5GC(5G Core Network) 和 NG-RAN(Next Generation Radio Access Network) NG接口链接核心网和接入网，实现控制面和用户面功能； Xn接口链接接入网，实现控制面和用户面功能。 接口为逻辑接口 gNB:5G基站 ng-eNB:增强4G基站 AMF/UPF/SMF 核心网网元 4G移动通信系统包括EPC(Evolved Packet Core network),演进分组核心网和E-UTRAN(Evolved Universal Terrestrial Radio Access Network)演进通用陆地无线接入网络 S1 X2 接口 5G 4G系统整体架构类似，区别如下： RAN网络引入 CU DU 组网灵活 MEC(Multi-access Edge Connection)多接入边缘计算是5G系统运行的关键技术，可实现5GC的部分功能，可将核心网部署在靠近基站的地方，降低时延。 关于前传中传回传 一个基站，通常包括BBU(Building Base band Unit，基带单元，主要负责信号调制)、RRU(Remote Radio Unit，主要负责射频处理)，馈线(连接RRU和天线)，天线(主要负责线缆上导行波和空气中空间波之间的转换)。4G每个基站都有一个BBU，并通过BBU直接连到核心网。 而在5G网络中，接入网不再是由BBU、RRU、天线这些东西组成了。而是被重构为以下3个功能实体： CU(Centralized Unit，集中单元)，DU(Distribute Unit，分布单元)，AAU(Active Antenna Unit，有源天线单元)。 原来4G的RRU和天线合并成AAU（方便大规模天线的实现），把BBU分离成CU和DU，DU下沉（见图1-3）到AAU处，一个CU可以连接多个DU。 4G只有前传和回传两部分，在5G网络中则演变为三个部分，AAU连接DU部分称为5G前传（Fronthaul），中传（Middlehaul）指DU连接CU部分，而回传（Backhaul）是CU和核心网之间的通信承载。 1.1.1 核心网架构演进 模拟通信：保密性差 数字通信：数字化，2.5G后可上网阶段 互联网：IP化，传输媒介发生改变，网线、光纤投入使用，设备围绕IP 端口进行，承载控制分离，网元功能细化。网业分离，分为控制面、用户面。3/4G阶段 SDN/NFV Software-defined Networking 软件定义网络 Network Functions Virtualization网络功能虚拟化， 网络架构颠覆，基于服务的网络架构，网元数量大量增加，UPF只用于 处理，控制处理分离，控制和用户完全的分离，软件硬件分离架构灵活 网元虚拟化易于操作 总结：模块化，虚拟化 4G核心网架构 各模块基于NFC实现虚线框内，为控制面 UPF为用户面，实现用户面控制面分离。 各网元功能见下节 1.1.2 无线接入网演进 “分合分”的表象 CU对实时性要求不高，实时性要求高在DU实现。 1.2 5G网元功能与接口 1.2.1 5G移动通信整体网络架构 网络功能间的信息交互基于两种方式表示：服务表示（模块名称前+N，指对外暴露的接口，多对一接口，用到服务注册和服务发现的功能，相互之间不需要知道功能所在的地址）、点对点表示（不同功能实体之间有约定好的接口，比较简单，不考虑注册和发现，但是拓展性弱）。 点对点表示如下图1-9 5GC各网元功能介绍 AMF Access and Mobility Management Function 接入和移动性管理功能 SMF Session Management function 会话管理功能 AUSF Authentication Server Function 认证服务器功能 UPF The User plane function 用户面功能 PCF Policy Control function 策略控制功能 UDM The Unified Data Management 统一数据管理功能 NRF NF Repository Function 网元存储功能 NSSF The Network Slice Selection Function 网络切片选择 NEF Network Exposure Function 网络开放功能 CU DU分离逻辑图： 层与层之间的交互： CU分为 CU-C C控制 CU-U U用户 内部接口： F1-C F1-U，对外接口Xn-C Xn-U 上图不代表实际连接情况，不等于gNB等于CU+DU 具体连接关系可调节。 CU DU有八种划分方式 CU便于集中化管理，DU便于更大传输带宽，更低时延。 3GPP(3rd Generation Partnership Project)标准确定了option2 1.2.2 5G主要网元功能 主要功能如下图： UPF（用户面功能） 掌握主要功能： gNB切换的本地移动锚点（适用时）：在不同地方使用网络确保连接连通，切换前后保持不变 连接到移动通信网络的外部PDU会话点 N接口切换过程中，数据匹配路径，路由与转发 Uplink流量验证（SDF到QoS流映射） SMF（会话管理功能） 终端发起寻呼，接入网可以响应，进行会话的建立 终端IP地址的分配和管理 选择合适的UPF 基于策略控制用户面功能 AMF（访问和移动性管理功能） NAS信令的加密和保护 注册管理 在UE和SMF直接传输SM消息，透传信息 gNB/en-gNB CU-C (Central Unit Control plane) 不同接口的管理和数据处理 连接管理包括：单连接 双连接 多链接 和D2D 系统内和系统间负载均衡 切片资源动态管理 CU-U 数据包的处理和转换 DU 资源调度、传输模式的转换、信道映射 AAU-RF(RAdio Frequency) 信号手法 Massive MIMO 大规模天线处理 频率时间同步 AAS实现机制 1.2.3 接口协议及功能 数据传输需遵循各个协议的要求，下面是主要接口 NG接口是接入网和核心网之间的接口，控制面和用户面分离 NG接口控制面功能流程描述 NG-U接口主要功能：用户面数据传送 Xn接口是基站之间的接口，分为控制面用户面 Xn-C是CU-C之间的接口，Xn-U是CU-U之间的接口 Xn-C接口功能流程描述 Xn-U主要功能 E1接口指CU-C与CU-U接口，只有控制面接口，支持信令信息的交换 F1接口是CU与DU之间的接口，支持信令交互，包括不同eNB-point的数据发送，包括控制面用户面 终端和基站之间的Uu接口 控制面：涉及终端、基站、核心网 NAS层属于控制面功能 用户面： 新的协议层SDAP层：业务适配层，完成流到无线承载的QoS映射，为每个报文打上流表示 1.3 5G网络组网部署 1.3.1 SA组网和NSA组网 NSA(Not standalon)：非独立：终端同一时间同时连接4g 5g基站 接入4g或5g的核心网 SA(standalone)：独立 区分根本不同：同一时间5g基站能否单独提供服务 原因：5g在刚刚引入时基站数量不足 SA组网方案：option2/5 option2:5gc–gNB option5:5gc–ng-eNB NAS组网部署： option3:4g 5g 基站合用4g核心网，控制面仅经由enb连接到epc，优势在于不必新增5G核心网，缺点是4g核心网有信令过载风险，该阶段主要解决初期的5g覆盖 option7:核心网变为5g核心网，控制网由ngenb连接到5gc，解决了4g核心网信令过载风险，主要面向5g容量需求 基站间接口变为Xn option4:控制面由gnb连接到5gc，该阶段不仅面向5g的增强型移动带宽场景（eMBB） 大规模物联网（mMTC）和低时延高可靠连接（URLLC），是面向万物连接时代5G的多样化业务 Ultra-Reliable and Low Latency Communications–URLLC Massive MachineType Communication–mMTC Enhanced Mobile Broadband–eMBB option4/7 不常用 5G核心网主要使用独立组网 3GPP协议下对基站定义： eNB 面向终端提供 E-UTRAN用户面控制面协议，通过S1接口连接EPC（4g核心网） ng-eNB 面向终端提供 E-UTRAN用户面控制面协议，通过NG接口连接5GC（5G核心网） gNB 面向终端提供NR用户面和控制面协议，通过NG接口连接到5GC en-gNB 面向终端提供NR用户面和控制面协议，通过S1-U接口连接到EPC的网络节点 SA NSA组网方案对比 1.3.2 MR-DC技术 Multi-RAT Dual Connectivity 多接入网技术双连接 一部终端可以同时连接4G 5G网络，同时使用两个网络进行业务，此时终端需要具备至少两个MAC实体，支持双发双收。 控制面协议栈 MN为主节点，SN辅节点，各自有RRC实体，可以生成要发送到终端的PDU，只有主节点才能连接到核心网 用户面承载概念 MCG(Master Cell Group):主小区组，和主节点相关呃校区 MCG承载的RLC实体一定落在主节点 SCG(Secondary Cell Group):辅小区组，和辅节点相关 SCG承载的RLC实体落在辅节点 分离承载：RLC实体既可以存在于主节点也可以存在于辅节点 承载可理解为用户面传递数据概念，从核心网数据经用户面传递的路径 有了双连接的概念，就有了MCG和SCG的概念。从信令交互角度来看，UE首先发起随机接入过程的小区（Cell）所在的组（Group）就是MCG。假若5G NR基站和LTE基站一起给UE提供双连接服务，LTE作主基站，5G NR基站作辅基站，那么LTE所提供的多个小区就是MCG（Master CellGroup，主小区组），5G NR提供的多个小区就是SCG（Secondary Cell Group，辅小区组）。MCG的小区和SCG的小区应该配置成邻小区关系。 5G组网MCG与SCG CA(Carrier Aggregation) 载波聚合 终端也与多个接入网网元连接，但是控制面连接仅有一个 5G NR协议栈 1.3.3 CU/DU组网部署 CU DU AAU三级配置可搭配处不同网络结构 为支持eMBB的覆盖和容量需求，CU DU 分离部署，分为Macro(宏)和Micro(微)方式 分离部署 两种方式相同 合设部署 DU+RRU-微组网部署 在密集部署条件下，联合多个DU形成基带池（时效性好），提高网络覆盖和容量，组网方式如下图 DU CU一起部署-&gt;大带宽低时延：视频、虚拟现实 DU CU分离-&gt;对带宽时延要求不高：语音业务 mMTC 缩略词解释","categories":[{"name":"大唐杯","slug":"大唐杯","permalink":"https://2incccc.github.io/categories/%E5%A4%A7%E5%94%90%E6%9D%AF/"}],"tags":[{"name":"5G","slug":"5G","permalink":"https://2incccc.github.io/tags/5G/"},{"name":"通信","slug":"通信","permalink":"https://2incccc.github.io/tags/%E9%80%9A%E4%BF%A1/"},{"name":"大唐杯","slug":"大唐杯","permalink":"https://2incccc.github.io/tags/%E5%A4%A7%E5%94%90%E6%9D%AF/"}]},{"title":"51单片机入门","slug":"51单片机入门","date":"2023-01-20T03:18:17.000Z","updated":"2025-01-27T07:36:53.463Z","comments":true,"path":"2023/01/20/51单片机入门/","link":"","permalink":"https://2incccc.github.io/2023/01/20/51%E5%8D%95%E7%89%87%E6%9C%BA%E5%85%A5%E9%97%A8/","excerpt":"课程来源：江科大自化协 1 单片机及开发板介绍 单片机 Micro Controller Unit 简称 MCU 内部集成 CPU RAM ROM 定时器 终端系统 通讯接口等一系列常用硬件功能 单片机的任务：信息采集、处理和硬件设备的控制 学习使用单片机是了解计算机原理与结构的最佳选择 STC89C52 单片机","text":"课程来源：江科大自化协 1 单片机及开发板介绍 单片机 Micro Controller Unit 简称 MCU 内部集成 CPU RAM ROM 定时器 终端系统 通讯接口等一系列常用硬件功能 单片机的任务：信息采集、处理和硬件设备的控制 学习使用单片机是了解计算机原理与结构的最佳选择 STC89C52 单片机 所属系列：51 单片机系列 公司：STC 公司 位数：8 位 RAM：512 字节 ROM：8K 工作频率：12MHz 是对所有兼容 Intel 8031 指令系统的单片机的统称 命名规则 工作电压、程序空间 RAM 大小、工作频率、温度范围、封装类型、管脚数 2 LED 2-1 LED 点亮 2-2 LED 闪烁 2-3 LED 流水灯 延时代码 12345678910111213141516void Delay500ms()//@12.000MHz&#123; unsigned char i, j, k; _nop_(); i = 4; j = 205; k = 187; do &#123; do &#123; while (--k); &#125; while (--j); &#125; while (--i);&#125; 3 按键开关 3-1 独立按键控制 LED 亮灭 轻触按键：按下开关接通、松开开关断开，原理：金属弹片受力弹动 根据原理图，按下按键对应值为 0； C51 数据运算 算术：+, -, *, /, %, = 判断： &gt;, &gt;=, &lt;, &lt;=, ==, != 逻辑: 运算符 意义 &amp;&amp; 逻辑与 || 逻辑或 ! 逻辑非 位运算 运算符 意义 &lt;&lt; 按位左移 &gt;&gt; 按位右移 &amp; 按位与 | 按位或 ^ 按位异或 ~ 按位去反 C51 基本语句 if for while switch 3-2 按键控制 LED 状态 按键抖动 在开关闭合及断开的瞬间会伴随一连串的抖动 消抖 硬件消抖： RS 触发器 电容器 软件消抖 延时函数 优点：简单方便 缺点：程序空跑浪费 CPU 资源 12345678910111213141516171819//@12.000MHz-1ms 延时函数void Delay(unsigned int xms)&#123;//延时1ms unsigned char i, j; while(xms--)&#123; i = 2; j = 239; do&#123; while (--j); &#125; while (--i); &#125;&#125;//消抖函数void debounce()&#123; if(PXin(x)==KEY_PRESS) //代表按下按键 Delay(10); //刚按下时出现抖动，延时10ms while(PXin(x)==KEY_PRESS); //按键闭合，不做处理 Delay(10); //按键弹起出现抖动，延时10ms /*按键处理*/&#125; 4 数码管 4-1 静态数码管显示 数码管介绍 动态数码管模块原理图 74HC138(U5): 三线-八线译码器，详见数电课本 74HC245(U4)： 作用：双向数据缓冲器，将数据由 AX 传至 BX 原因：单片机驱动能力弱，将驱动改为控制信号，使 LED 数码管的驱动能力来源 VCC RP3&amp;4 100R 100 欧姆排阻 作用：分流 应用原理 74HC138 译码器，输入三位 421 二进制数，输出结果作为位码 74HC245，八位输入作为段码 C51 数组 12int x[3]; //定义一组变量int x[]=&#123;1,2,3&#125;; //定义一组变量并初始化 C51 子函数 将完成某一功能的程序代码单独抽取出来形成一个模块，在其他函数中可随时调用此模块，以达到代码的复用和优化程序结构的目的。 数码管段码表 12345678910111213141516171819202122232425uchar code table［］=&#123; /*共阳极，位选高电平有效，段选低电平有效*/ 0xc0，//0 0xf9，//1 0xa4，//2 0xb0，//3 0x99，//4 0x92，//5 0x82，//6 0xf8，//7 0x80，//8 0x90，//9 0x88，//A 0x83，//B 0xc6，//C 0xa1，//D 0x86，//E 0x8e, //F 0x8c, //P 0xc1,//U 0x91,//Y 0x7c,//L 0x00,//全亮 0xff //熄灭&#125;; 123456789101112131415161718192021222324252627uchar code leddata[]=&#123; /*共阴极，位选低电平有效，段选高电平有效*/ 0x3F, //&quot;0&quot; 0x06, //&quot;1&quot; 0x5B, //&quot;2&quot; 0x4F, //&quot;3&quot; 0x66, //&quot;4&quot; 0x6D, //&quot;5&quot; 0x7D, //&quot;6&quot; 0x07, //&quot;7&quot; 0x7F, //&quot;8&quot; 0x6F, //&quot;9&quot; 0x77, //&quot;A&quot; 0x7C, //&quot;B&quot; 0x39, //&quot;C&quot; 0x5E, //&quot;D&quot; 0x79, //&quot;E&quot; 0x71, //&quot;F&quot; 0x76, //&quot;H&quot; 0x38, //&quot;L&quot; 0x37, //&quot;n&quot; 0x3E, //&quot;u&quot; 0x73, //&quot;P&quot; 0x5C, //&quot;o&quot; 0x40, //&quot;-&quot; 0x00 //熄灭 &#125;; 4-2 动态数码管显示 数码管串位现象（数码管消影）下一次位选和上一次段选重合。 解决方式：在下一次位选之前段选清零 1234//....P0=NixieTable[Number];Delay(1);P0=0x00； //清零 数码管驱动方式 单片机直接扫描（动态扫描） 硬件设备简单，但会耗费大量的单片机 CPU 时间 专用驱动芯片 内部自带现存、扫描电路，单片机只需告诉它显示什么即可 5 编程与调试 5-1 模块化编程 传统方式编程 所有函数在 main.c，模块较多则不利于代码组织与管理，影响思路。 模块化编程 将模块独立放在不同的.c 文件，在.h 文件里提供外部可调用函数的声明，其他.c 文件想使用其中的代码，只需 include 调用即可。使用模块化编程课极大提高代码的可阅读性、可维护性、可移植性等。 fun.c-&gt;fun.h-&gt;main.c 模块化编程的注意事项 .c 文件：函数、变量的定义 .h 文件：可被外部调用的函数、变量的声明 任何自定义的变量、函数在调用前有定义或声明 使用到的自定义函数的.c 需参与编译 使用到的.h 文件必须要放在百年一起可寻找到的地方（工程文件夹根目录、安装目录、自定义） C 预编译 以#开头，在编译前对代码做出的一些处理 5-2 LCD1602 调试工具 常用函数 1234567void LCD_Init();void LCD_ShowChar(unsigned char Line,unsigned char Column,char Char);void LCD_ShowString(unsigned char Line,unsigned char Column,char *String);void LCD_ShowNum(unsigned char Line,unsigned char Column,unsigned int Number,unsigned char Length);void LCD_ShowSignedNum(unsigned char Line,unsigned char Column,int Number,unsigned char Length);void LCD_ShowHexNum(unsigned char Line,unsigned char Column,unsigned int Number,unsigned char Length);void LCD_ShowBinNum(unsigned char Line,unsigned char Column,unsigned int Number,unsigned char Length); 函数定义详见LCE1602.c 6 矩阵键盘 6-1 矩阵键盘 为节省 IO 口，逐行逐列扫描，可读出任何位置按键的状态 6-2 矩阵键盘密码锁 矩阵键盘+LCD1602 补充：单行清屏显示 123456789101112131415//第二行的清除函数void LCD1602_Clear_2LINE()&#123; int i=0; LCD_WriteCommand(0x80+0x40); for(i=0;i&lt;16;i++) &#123; LCD_WriteData(0x20); //无显示 &#125;//详见函数定义文件及LCD指令集&#125; 7 定时器 7-1 定时器 定时器介绍：51 单片机的定时器属于单片机的内部资源，其电路的连接和运转均在单片机内部完成 定时器作用： （1）用于计时系统，可实现软件计时，或者使程序每隔一固定时间完成一项操作 （2）替代长时间的 Delay，提高 CPU 的运行效率和处理速度 （…） 定时器工作模式 模式 0：13 位定时器/计数器 模式 1：16 位定时器/计数器 模式 2：8 位自动重装模式 模式 3：两个 8 位定时器 时钟来源： 系统时钟（晶振周期），本开发板晶振的频率 12MHz，周期 1/12us,机器周期为 12*1/12us=1us 外部 IO 口时钟（T0-P3.4,T1-P3.5） 定时器和计数器： 二者核心部件都是一个加减法计数器，其本质相同均为对脉冲进行计数 区别在于定时器的计数脉冲来自系统时钟，计数器的计数脉冲来自外部时钟 中断系统 是为使 CPU 具有对外界紧急事件的实时处理能力而设置的。 CPU 总是先相应优先级别最高的中断请求。 相关寄存器 51单片机内计时器是由特殊的功能寄存器控制 寄存器是连接软硬件的媒介 在单片机中寄存器就是一段特殊的 RAM 存储器，一方面，寄存器可以存储和读取数据，另一方面，每一个寄存器背后都连接了一根导线，控制着电路的连接方式 寄存器相当于一个复杂机器的“操作按钮” 具体定义详见手册 控制寄存器TCON： 低四位：外部中断的控制位 高四位用于定时器启动、停止、移除的标志控制位 模式寄存器TMOD：定时器工作方式及功能的确定（定时|计数） 7-2 按键控制 LED 流水灯模式&amp;定时器闹钟","categories":[],"tags":[{"name":"电赛","slug":"电赛","permalink":"https://2incccc.github.io/tags/%E7%94%B5%E8%B5%9B/"},{"name":"51单片机","slug":"51单片机","permalink":"https://2incccc.github.io/tags/51%E5%8D%95%E7%89%87%E6%9C%BA/"},{"name":"Keil","slug":"Keil","permalink":"https://2incccc.github.io/tags/Keil/"}]}],"categories":[{"name":"juce开发","slug":"juce开发","permalink":"https://2incccc.github.io/categories/juce%E5%BC%80%E5%8F%91/"},{"name":"d2l.ai","slug":"d2l-ai","permalink":"https://2incccc.github.io/categories/d2l-ai/"},{"name":"微机原理与接口技术","slug":"微机原理与接口技术","permalink":"https://2incccc.github.io/categories/%E5%BE%AE%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B8%8E%E6%8E%A5%E5%8F%A3%E6%8A%80%E6%9C%AF/"},{"name":"数字音视频原理","slug":"数字音视频原理","permalink":"https://2incccc.github.io/categories/%E6%95%B0%E5%AD%97%E9%9F%B3%E8%A7%86%E9%A2%91%E5%8E%9F%E7%90%86/"},{"name":"Music Information Retrieval","slug":"Music-Information-Retrieval","permalink":"https://2incccc.github.io/categories/Music-Information-Retrieval/"},{"name":"数学建模教程","slug":"数学建模教程","permalink":"https://2incccc.github.io/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%95%99%E7%A8%8B/"},{"name":"音频信号处理及深度学习教程","slug":"音频信号处理及深度学习教程","permalink":"https://2incccc.github.io/categories/%E9%9F%B3%E9%A2%91%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E5%8F%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B/"},{"name":"大唐杯","slug":"大唐杯","permalink":"https://2incccc.github.io/categories/%E5%A4%A7%E5%94%90%E6%9D%AF/"}],"tags":[{"name":"juce","slug":"juce","permalink":"https://2incccc.github.io/tags/juce/"},{"name":"cmake","slug":"cmake","permalink":"https://2incccc.github.io/tags/cmake/"},{"name":"工具","slug":"工具","permalink":"https://2incccc.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"name":"效率","slug":"效率","permalink":"https://2incccc.github.io/tags/%E6%95%88%E7%8E%87/"},{"name":"经验分享","slug":"经验分享","permalink":"https://2incccc.github.io/tags/%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB/"},{"name":"笔记","slug":"笔记","permalink":"https://2incccc.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"论文","slug":"论文","permalink":"https://2incccc.github.io/tags/%E8%AE%BA%E6%96%87/"},{"name":"Dance Generation","slug":"Dance-Generation","permalink":"https://2incccc.github.io/tags/Dance-Generation/"},{"name":"Motion Generation","slug":"Motion-Generation","permalink":"https://2incccc.github.io/tags/Motion-Generation/"},{"name":"d2l.ai","slug":"d2l-ai","permalink":"https://2incccc.github.io/tags/d2l-ai/"},{"name":"深度学习","slug":"深度学习","permalink":"https://2incccc.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"机器学习","slug":"机器学习","permalink":"https://2incccc.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"AutoML","slug":"AutoML","permalink":"https://2incccc.github.io/tags/AutoML/"},{"name":"自动机器学习","slug":"自动机器学习","permalink":"https://2incccc.github.io/tags/%E8%87%AA%E5%8A%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"AI4AI","slug":"AI4AI","permalink":"https://2incccc.github.io/tags/AI4AI/"},{"name":"ARM","slug":"ARM","permalink":"https://2incccc.github.io/tags/ARM/"},{"name":"微机原理","slug":"微机原理","permalink":"https://2incccc.github.io/tags/%E5%BE%AE%E6%9C%BA%E5%8E%9F%E7%90%86/"},{"name":"数字音视频","slug":"数字音视频","permalink":"https://2incccc.github.io/tags/%E6%95%B0%E5%AD%97%E9%9F%B3%E8%A7%86%E9%A2%91/"},{"name":"音乐信息检索","slug":"音乐信息检索","permalink":"https://2incccc.github.io/tags/%E9%9F%B3%E4%B9%90%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2/"},{"name":"数学建模","slug":"数学建模","permalink":"https://2incccc.github.io/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"},{"name":"规划，数学建模老哥","slug":"规划，数学建模老哥","permalink":"https://2incccc.github.io/tags/%E8%A7%84%E5%88%92%EF%BC%8C%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E8%80%81%E5%93%A5/"},{"name":"音频信号","slug":"音频信号","permalink":"https://2incccc.github.io/tags/%E9%9F%B3%E9%A2%91%E4%BF%A1%E5%8F%B7/"},{"name":"声学","slug":"声学","permalink":"https://2incccc.github.io/tags/%E5%A3%B0%E5%AD%A6/"},{"name":"神经网络","slug":"神经网络","permalink":"https://2incccc.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"信号处理","slug":"信号处理","permalink":"https://2incccc.github.io/tags/%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/"},{"name":"人工智能","slug":"人工智能","permalink":"https://2incccc.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"5G","slug":"5G","permalink":"https://2incccc.github.io/tags/5G/"},{"name":"通信","slug":"通信","permalink":"https://2incccc.github.io/tags/%E9%80%9A%E4%BF%A1/"},{"name":"大唐杯","slug":"大唐杯","permalink":"https://2incccc.github.io/tags/%E5%A4%A7%E5%94%90%E6%9D%AF/"},{"name":"电赛","slug":"电赛","permalink":"https://2incccc.github.io/tags/%E7%94%B5%E8%B5%9B/"},{"name":"51单片机","slug":"51单片机","permalink":"https://2incccc.github.io/tags/51%E5%8D%95%E7%89%87%E6%9C%BA/"},{"name":"Keil","slug":"Keil","permalink":"https://2incccc.github.io/tags/Keil/"}]}